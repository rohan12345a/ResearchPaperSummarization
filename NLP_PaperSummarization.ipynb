{
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**RESEARCH PAPER SUMMARIZATION**"
      ],
      "metadata": {
        "id": "S0yF3zlg6z5q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PROBLEM STATEMENT**\n",
        "\n",
        "The problem we're addressing is that research papers are often long and difficult to understand, making thorough reading time-consuming and tricky. Abstracts provide limited information and may miss crucial details. Our goal is to develop a computer program that generates concise, easy-to-understand summaries of these lengthy papers, capturing all essential points accurately. This way, users can quickly grasp key findings without reading the entire paper.\n"
      ],
      "metadata": {
        "id": "-_SWcbRT7OHA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DATASET DESCRIPTION**\n",
        "\n",
        "The Random Research Papers Dataset comprises a collection of over 600 research papers sourced from various sources on the web. Through a meticulous selection process, approximately 350 of the most relevant and high-quality papers have been curated for inclusion in this dataset.\n",
        "\n",
        "Contents:\n",
        "\n",
        "The dataset includes research papers covering a wide range of topics and disciplines, reflecting the diverse nature of academic research.\n",
        "Each paper is accompanied by relevant metadata such as title, authors, publication source, abstract, and publication date (if available).\n",
        "The papers cover various fields of study, including but not limited to, computer science, medicine, engineering, social sciences, and more."
      ],
      "metadata": {
        "id": "gPTelbqH7o_c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORTING LIBRARIES**"
      ],
      "metadata": {
        "id": "qafDDWdW7cxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymupdf\n",
        "!pip install pycryptodome\n",
        "import os\n",
        "import fitz  # PyMuPDF\n",
        "import pandas as pd\n",
        "from multiprocessing import Pool"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9x2SQWQGjx5c",
        "outputId": "bbe53e88-7389-4767-f2e5-4cd7ee1fab06",
        "execution": {
          "iopub.status.busy": "2023-10-23T22:07:56.473661Z",
          "iopub.execute_input": "2023-10-23T22:07:56.474128Z",
          "iopub.status.idle": "2023-10-23T22:08:28.468298Z",
          "shell.execute_reply.started": "2023-10-23T22:07:56.474084Z",
          "shell.execute_reply": "2023-10-23T22:08:28.466924Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting pymupdf\n  Downloading PyMuPDF-1.23.5-cp310-none-manylinux2014_x86_64.whl (4.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting PyMuPDFb==1.23.5 (from pymupdf)\n  Downloading PyMuPDFb-1.23.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (30.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.6/30.6 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: PyMuPDFb, pymupdf\nSuccessfully installed PyMuPDFb-1.23.5 pymupdf-1.23.5\nRequirement already satisfied: pycryptodome in /opt/conda/lib/python3.10/site-packages (3.18.0)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Python script extracts text from a collection of PDF research papers, excluding tables, diagrams, and graphs, and stores the information in a DataFrame for analysis."
      ],
      "metadata": {
        "id": "ZhPKMmIn93BH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the path to your folder containing PDFs\n",
        "pdf_folder = \"/kaggle/input/researchpaper-alldata\"\n",
        "\n",
        "# Initializin the an empty list to store the data\n",
        "pdf_data = []\n",
        "\n",
        "# Defining the keywords that indicate the start of the references section\n",
        "references_start_keywords = [\"Bibliography\", \"REFERENCES\", \"BIBLIOGRAPHY\", \"References\", \"Acknowledgments\",\n",
        "                             \"ACKNOWLEDGEMENTS\", \"Reference\", \"REFERENCE\", \"Authors’ Biography\"]\n",
        "\n",
        "# Function to extract text from the PDF, excluding tables, diagrams, and graphs\n",
        "def extract_text_from_pdf_exclude_elements(pdf_path):\n",
        "    text = \"\"\n",
        "    pdf_document = fitz.open(pdf_path)\n",
        "    exclude_text = False  # Flag to indicate whether to exclude text after references_start_keywords\n",
        "\n",
        "    for page_number in range(pdf_document.page_count):\n",
        "        page = pdf_document.load_page(page_number)\n",
        "\n",
        "        # Checking if any of the references start keywords are present in the page text\n",
        "        if any(keyword in page.get_text() for keyword in references_start_keywords):\n",
        "            exclude_text = True  # Set the flag to exclude text from this point\n",
        "            break  # Stop text extraction after encountering references_start_keywords\n",
        "\n",
        "        if not exclude_text:\n",
        "            page_text = page.get_text(\"text\")\n",
        "            # Checking if the page contains any images and exclude them\n",
        "            if not page.get_images():\n",
        "                if page_text.strip():  # Checking if the extracted text is not empty\n",
        "                    text += page_text\n",
        "\n",
        "    return text\n",
        "\n",
        "# Multiprocessing for parallelization Takes pdf\n",
        "def process_pdf(pdf_file):\n",
        "    pdf_path = os.path.join(pdf_folder, pdf_file)\n",
        "    text = extract_text_from_pdf_exclude_elements(pdf_path)\n",
        "    return {'Research_Paper_Name': pdf_file, 'source': text}\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    pdf_files = [file_name for file_name in os.listdir(pdf_folder) if file_name.endswith('.pdf')]\n",
        "\n",
        "    # Defining the number of CPU cores to use for parallelization\n",
        "    num_cores = os.cpu_count()\n",
        "\n",
        "    with Pool(processes=num_cores) as pool:\n",
        "        pdf_data = pool.map(process_pdf, pdf_files)\n",
        "\n",
        "    # Filtering out PDFs with no text output\n",
        "    pdf_data = [item for item in pdf_data if item['source']]  # Removes items from pdf_data where the 'source' key is empty (no text was extracted).\n",
        "\n",
        "    # Creating a DataFrame\n",
        "    df = pd.DataFrame(pdf_data)\n",
        "\n",
        "    # Displaying the DataFrame\n",
        "    print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "HQ-9Gu8PRH77",
        "outputId": "f22b09c7-680f-4f5b-d9f4-a77a25fedc44",
        "execution": {
          "iopub.status.busy": "2023-10-23T22:08:28.471149Z",
          "iopub.execute_input": "2023-10-23T22:08:28.471833Z",
          "iopub.status.idle": "2023-10-23T22:10:11.067252Z",
          "shell.execute_reply.started": "2023-10-23T22:08:28.471770Z",
          "shell.execute_reply": "2023-10-23T22:10:11.065707Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "                                   Research_Paper_Name  \\\n0                                       2210.00881.pdf   \n1                                   TSP_CSSE_45181.pdf   \n2                             electronics-11-00325.pdf   \n3    Performance_of_Deep-Learning_Solutions_on_Lung...   \n4                                    9789392995101.pdf   \n..                                                 ...   \n341                              ASAfilippi_p_558s.pdf   \n342                               25894-50878-1-PB.pdf   \n343           Women_Empowerment_in_Bangladesh_NGOS.pdf   \n344                           diagnostics-12-00203.pdf   \n345                       20220122011404pmWEB19034.pdf   \n\n                                                source  \n0    Predicting the Future of AI with AI:\\nHigh-Qua...  \n1    Insider Attack Detection Using Deep Belief Neu...  \n2    Electronics 2022, 11, 325\\n2 of 18\\nartiﬁcial ...  \n3    Life 2023, 13, 1911\\n2 of 13\\neffective in red...  \n4     \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n ...  \n..                                                 ...  \n341  Detecting causes of spatial variation in crop ...  \n342  Int J Elec & Comp Eng  \\nISSN: 2088-8708 \\n \\...  \n343  NU Journal of Humanities, Social Sciences & Bu...  \n344  Diagnostics 2022, 12, 203 \\n2 of 17 \\n \\n \\n(A...  \n345  Webology, Volume 19, Number 1, January, 2022 \\...  \n\n[346 rows x 2 columns]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df['source'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCL7Lv-xRH79",
        "outputId": "0a83a638-a325-425f-dfac-3947f5288af4",
        "execution": {
          "iopub.status.busy": "2023-10-23T22:10:11.069677Z",
          "iopub.execute_input": "2023-10-23T22:10:11.070628Z",
          "iopub.status.idle": "2023-10-23T22:10:11.079446Z",
          "shell.execute_reply.started": "2023-10-23T22:10:11.070592Z",
          "shell.execute_reply": "2023-10-23T22:10:11.078536Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 3,
          "output_type": "execute_result",
          "data": {
            "text/plain": "28301"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['source'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARQ5pGN1RH79",
        "outputId": "ecc4a410-ab30-4b5b-fd83-d1e90cf47cd0",
        "execution": {
          "iopub.status.busy": "2023-10-23T22:10:11.082508Z",
          "iopub.execute_input": "2023-10-23T22:10:11.082871Z",
          "iopub.status.idle": "2023-10-23T22:10:11.094213Z",
          "shell.execute_reply.started": "2023-10-23T22:10:11.082836Z",
          "shell.execute_reply": "2023-10-23T22:10:11.092983Z"
        },
        "_kg_hide-output": false,
        "_kg_hide-input": false,
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Predicting the Future of AI with AI:\nHigh-Quality link prediction in an exponentially growing knowledge network\nMario Krenn,1, ∗ Lorenzo Buﬀoni,2 Bruno Coutinho,2 Sagi Eppel,3 Jacob Gates Foster,4\nAndrew Gritsevskiy,3, 5, 6 Harlin Lee,4 Yichao Lu,7 Jo˜ao P. Moutinho,2 Nima Sanjabi,8 Rishi Sonthalia,4\nNgoc Mai Tran,9 Francisco Valente,10 Yangxinyu Xie,11 Rose Yu,12 and Michael Kopp6\n1Max Planck Institute for the Science of Light (MPL), Erlangen, Germany.\n2Instituto de Telecomunica¸c˜oes, Lisbon, Portugal.\n3University of Toronto, Canada.\n4University of California Los Angeles, USA.\n5Cavendish Laboratories, Cavendish, Vermont, USA.\n6Institute of Advanced Research in Artiﬁcial Intelligence (IARAI), Vienna, Austria.\n7Layer 6 AI, Toronto, Canada.\n8Independent Researcher, Barcelona, Spain.\n9University of Texas at Austin, USA.\n10Independent Researcher, Leiria, Portugal.\n11University of Pennsylvania, USA.\n12University of California, San Diego, USA.\nA tool that could suggest new personalized research directions and ideas by taking insights from\nthe scientiﬁc literature could signiﬁcantly accelerate the progress of science.\nA ﬁeld that might\nbeneﬁt from such an approach is artiﬁcial intelligence (AI) research, where the number of scientiﬁc\npublications has been growing exponentially over the last years, making it challenging for human\nresearchers to keep track of the progress. Here, we use AI techniques to predict the future research\ndirections of AI itself. We develop a new graph-based benchmark based on real-world data – the\nScience4Cast benchmark, which aims to predict the future state of an evolving semantic network\nof AI. For that, we use more than 100,000 research papers and build up a knowledge network with\nmore than 64,000 concept nodes. We then present ten diverse methods to tackle this task, ranging\nfrom pure statistical to pure learning methods.\nSurprisingly, the most powerful methods use a\ncarefully curated set of network features, rather than an end-to-end AI approach. It indicates a great\npotential that can be unleashed for purely ML approaches without human knowledge. Ultimately,\nbetter predictions of new future research directions will be a crucial component of more advanced\nresearch suggestion tools.\nI.\nINTRODUCTION AND MOTIVATION\nThe corpus of scientiﬁc literature grows at an ever-\nincreasing speed. Speciﬁcally, in the ﬁeld of Artiﬁ-\ncial Intelligence (AI) and Machine Learning (ML),\nthe number of papers every month grows exponen-\ntially with a doubling rate of roughly 23 months\n(see Fig. 1). Simultaneously, the AI community is\nembracing diverse ideas from many disciplines such\nas mathematics, statistics, and physics, making it\nchallenging to organize diﬀerent ideas and uncover\nnew scientiﬁc connections. We envision a computer\nprogram that can automatically read, comprehend\nand act on AI literature. It can predict and suggest\nmeaningful research ideas that transcend individual\nknowledge and cross-domain boundaries. If success-\nful, it could signiﬁcantly improve the productivity\nof AI researchers, open up new avenues of research,\nand help drive progress in the ﬁeld.\nHere, we address this important and challenging\n∗ mario.krenn@mpl.mpg.de\nvision. New research ideas often result from drawing\nnovel connections between seemingly unrelated con-\ncepts [1–3]. Therefore, we formulate the evolution of\nAI literature as a temporal network modelling task.\nWe created an evolving semantic network character-\nizing the content and evolution of the scientiﬁc liter-\nature in the ﬁeld of AI since 1994. The network con-\ntains about 64,000 nodes (each representing a con-\ncept used in an AI paper) and 18 million edges that\nconnect two concepts when they were investigated\njointly in a scientiﬁc paper.\nWe use the semantic network as an input to 10\ndiverse statistical and machine-learning methods to\npredict the future evolution of the semantic network\nwith high accuracy. That is, we can predict which\ncombinations of concepts AI researchers will investi-\ngate in the future. Being able to predict what scien-\ntists will work on is a ﬁrst crucial step for suggesting\nnew topics that might have a high impact.\nSeveral of the methods presented in this paper\nhave been contributions to the Science4Cast com-\npetition hosted by IEEE BigData 2021, which ran\nfrom August to November 2021.\nBroadly, we can\ndivide the methods into two classes: methods that\narXiv:2210.00881v1  [cs.AI]  23 Sep 2022\n4\nB.\nNetwork-Theoretical Analysis\nWe start by analyzing the degree distribution\nof the published semantic network.\nThe network\nhas 64,719 nodes and 17,892,352 unique undirected\nedges, which implies a mean node degree of about\n553. However, the network contains many hub nodes\nthat signiﬁcantly exceed this mean degree, demon-\nstrated by the heavy-tail degree distribution in Fig.\n3. For example, the ten highest node degrees (and\ntheir corresponding concepts) are 466,319 (neural\nnetwork),\n198,050\n(deep learning),\n195,345\n(machine learning),\n169,555\n(convolutional\nneural network), 159,403 (real world), 150,227\n(experimental result),\n127,642\n(deep neural\nnetwork), 115,334 (large scale), 89,267 (high\ndimension), and 84,956 (high dimensional).\nTo investigate whether this complex network is\nscale-free, we ﬁt a power-law curve to the degree\ndistribution p(k) using [25], and the software ﬁt\np(k) ∝ k−2.28 for degree k ≥ 1672. Nevertheless,\nthe degree distribution of real complex network do\nnot always follow perfect power-laws and power-laws\nwith exponential cut-oﬀs are often a better ﬁt than\npure power-laws [26].\nA recent work [27] empirically showed that log-\nnormal distributions ﬁt most real-world networks as\nwell as or better than power laws, and conﬁrmed\nthat pure “scale-free networks are rare”.\nIn light\nof that result, we used likelihood ratio tests to com-\npare the power law ﬁt with alternative distributions.\nThe likelihood ratio tests from [25] suggested that\ntruncated power law (p-value: 0.0031), lognormal\n(p-value: 0.0045), and lognormal positive (p-value:\n0.015) ﬁt the data better than power law, while ex-\n101\n102\n103\n104\n105\nNode degree (log scale)\n100\n101\n102\n# of nodes (log scale)\n(64, 313)\nNeural Network\nVideo Compression Technique\nDegree distribution\nFigure 3.\nNode degrees follow heavy-tail distri-\nbution due to the hubs.\nNodes with the largest\n(466,319) and smallest (2) non-zero degrees correspond\nto neural network and video compression technique,\nrespectively. The most common non-zero degree is 64.\n1,247 nodes with zero degrees are not shown in this plot,\nand both axes are in log scale.\n1995\n2000\n2005\n2010\n2015\n2020\nYear\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\n# of CCs with >1 Nodes\n0\n1\n2\n3\n4\n5\n6\nSize of the Largest CC (in 10,000s)\nConnected Components (CCs)\nFigure 4.\nThe network became more connected\nover the years.\nPrimary (left, blue) vertical axis:\nNumber of connected components with more than one\nnode. Secondary (right, orange) vertical axis: Number\nof nodes in the largest connected component. For exam-\nple, the network in 2019 comprises of one large connected\ncomponent with 63,472 nodes and 1,247 isolated nodes,\ni.e. nodes with no edges. On the other hand, the 2001\nnetwork has 19 connected components with size greater\nthan one, the largest of which has 2,733 nodes.\nponential (p-value: 3e-10) and stretched exponen-\ntial (p-value: 6e-05) were worse. We could not con-\nclude whether truncated power law, lognormal, or\nlognormal positive best describe the data with p-\nvalue ≤ 0.1.\nNext, we discuss changes in the network con-\nnectivity over time.\nWhile the degree distri-\nbutions maintained a heavy tail over the years,\nthe ordering of the nodes inside the heavy tail\nchanged, likely in response to the popularity trends\nin the ﬁeld.\nThe nodes with most connections\n(and the year they became so) are decision tree\n(1994), machine learning (1996), logic program\n(2000),\nneural network\n(2005),\nexperimental\nresult (2011), machine learning (2013), and ﬁ-\nnally, back to neural network (2015).\nFurthermore, the network grew more connected\nover time according to connected component anal-\nysis in Fig.\n4.\nGroups that were previously sep-\narated became connected, i.e.\nnumber of con-\nnected components decreased, while the largest\ngroup grew bigger.\nThe trajectory of the mid-\nsized connected components may reveal interesting\ntrends about their topics.\nTake image processing\nfor instance. A connected component of the follow-\ning 4 nodes appeared in 1999: brightness change,\nplanar curve, local feature, and differential\ninvariant.\nIn 2000, 3 more nodes joined the\ngroup:\nsimilarity transformation,\ntemplate\nmatching, and invariant representation. Then\nin 2006,\na paper that discusses both support\nvector machine and local feature merged this\n7\n[31] and applies heavy regularization to combat over-\nﬁtting due to the scarcity of positive samples. The\ngraph neural network approach employs a time-\naware graph neural network to learn node represen-\ntations on dynamic semantic networks.\nB.\nM2: Features+ML\nThe method proposed by Team HashBrown as-\nsumes that the probability that nodes u and v form\nan edge in the future is a function of the node fea-\ntures f(u), f(v), and some edge feature h(u, v). We\nchose node features f that capture popularity at the\ncurrent time t0 (such as degree, clustering coeﬃcient\n[32, 33], and PageRank [30]). We also use these fea-\ntures’ ﬁrst and second time-derivatives to capture\nthe evolution of the node’s popularity over time. Af-\nter variable selection during training, we chose h to\nconsist of the HOP-rec score [34, 35] and a variation\nof the Dice similarity score [36] as a measure of sim-\nilarity between nodes. In summary, we use 31 node\nfeatures for each node, and two edge features, which\ngives 31 × 2 + 2 = 64 features in total. These fea-\ntures are then fed into a small multilayer perceptron\n(MLP) (5 layers, each with 13 neurons) with ReLU\nactivation.\nCold start is the problem that some nodes in the\ntest set do not appear in the training set. Our strat-\negy for a cold start is imputation. We say a node v\nis seen if it appeared in the training data, and un-\nseen otherwise; similarly, we say that a node is born\nat time t if t is the ﬁrst time stamp where an edge\nlinking this node has appeared. The idea is that an\nunseen node is simply a node born in the future, so\nits features should look like a recently born node in\nthe training set. If a node is unseen, then we im-\npute its features as the average of the features of\nthe nodes born recently. We found that with impu-\ntation during training, the test AUC scores across\nall models consistently increased by about 0.02. For\na complete description of this method, we refer the\nreader to [37].\nC.\nM3: Features+ML\nThis approach, detailed in [38], uses hand-crafted\nnode features that have been captured in multiple\ntime snapshots (e.g. every year) and then uses an\nLSTM to beneﬁt from learning the time dependen-\ncies of these features. The ﬁnal conﬁguration uses\ntwo main types of features: node features includ-\ning degree and degree of neighbours, and edge fea-\ntures including common neighbours. And to balance\nthe training data the same number of positive and\nnegative instances have been randomly sampled and\ncombined.\nOne of the goals was to identify features that are\nvery informative with a very low computational cost.\nWe found that the degree centrality of the nodes\nis the most important feature, and the degree cen-\ntrality of the neighbouring nodes and the degree of\nmutual neighbours gave us the best tradeoﬀ.\nAs\nall of the extracted features distributions are highly\nskewed to the right, meaning most of the features\ntake near zero values, using a power transform like\nYeo-Johnson [39] helps to make the distributions\nmore Gaussian which boosts the learning. Finally,\nfor the link prediction task, we saw that LSTMs per-\nform better than fully connected neural networks.\nD.\nM4: pure Features\nThe following two methods are based on a purely\nstatistical analysis of the test data and are explained\nin detail in [40].\nPreferential Attachment – In the network\nanalysis we concluded that the growth of this dataset\ntends to maintain a heavy-tailed degree distribu-\ntion, often associated with scale-free networks. As\nmentioned before the γ-value of the degree distribu-\ntion is very close to 2, suggesting that preferential-\nattachment [41] is likely the main organizational\nprinciple of the network. As such, we implemented\na simple prediction model following this procedure.\nPreferential-attachment scores in link prediction are\noften quantiﬁed as\nsPA\nij = ki · kj.\n(1)\nwith ki,j the degree of nodes i and j. However, this\nassumes the scoring of links between nodes that are\nalready connected to the network, that is ki,j > 0,\nwhich is not the case for all the links we must score\nin the dataset. As a result, we deﬁne our preferential\nattachment model as\nsPA\nij = ki + kj.\n(2)\nUsing this simple model with no free parameters we\ncould score new links and compare them with the\nother models. Immediately we note that preferential\nattachment outperforms some learning-based mod-\nels, even if it never manages to reach the top AUC,\nbut it is extremely simple and with negligible com-\nputational cost.\nCommon Neighbours – We explore another\nnetwork-based approach to score the links. Indeed,\nwhile the preferential attachment model we derived\nperformed well, it uses no information about the dis-\ntance between i and j, which is a popular feature\n8\nused in link prediction methods [22].\nAs such we\ndecided to test a method known as Common Neigh-\nbours [13].\nIf we deﬁne Γ(i) ∩ Γ(j) as the set of\ncommon neighbours between nodes i and j. We can\neasily score the nodes with\nsCN\nij\n= |Γ(i) ∩ Γ(j)|\n(3)\nthe intuition being that nodes which share a larger\nnumber of neighbours are more likely to be con-\nnected than distant nodes that do not share any.\nEvaluating this score for each pair (i, j) on the\ndataset of unconnected pairs, which can be com-\nputed as the second power of the adjacency matrix,\nA2, we obtained an AUC which is sometimes higher\nthan preferential attachment and sometimes lower\nthan it but is still consistently quite close with the\nbest learning-based models.\nE.\nM5: Features + ML\nThis method is based on [42] with a modiﬁca-\ntion disclosed in the VI C. First, 10 groups of ﬁrst-\norder graph features are extracted to get some neigh-\nbourhood and similarity properties from each pair\nof nodes:\ndegree centrality of nodes, pair’s total\nnumber of neighbours, common neighbours index,\nJaccard coeﬃcient, Simpson coeﬃcient, geometric\ncoeﬃcient, cosine coeﬃcient, Adamic-Adar index,\nresource allocation index, and preferential attach-\nment index. They are obtained for three consecu-\ntive years to capture the temporal dynamics of the\nsemantic network, leading to a total of 33 features.\nSecond, principal component analysis (PCA) [43] is\napplied to reduce the correlation between features,\nspeed up the learning process and improve general-\nization, which results in a ﬁnal set of 7 latent vari-\nables. Lastly, a random forest classiﬁer is trained\n(using a balanced dataset) to estimate the likelihood\nof new links between the AI concepts.\nF.\nM6: Features+ML\nThe baseline solution for the Science4Cast com-\npetition was closely related to the model presented\nin [12]. It uses 15 hand-crafted features of a pair of\nnodes v1 and v2 (Degrees of v1 and v2 in the current\nyear and previous two years, these are six proper-\nties. The number of shared neighbours in total of v1\nand v2 in the current year and previous two years are\nsix properties. The number of shared neighbours be-\ntween v1 and v2 in the current year and the previous\ntwo years, these are 3 properties). These 15 features\nare the input of a neural network with four layers\n(15, 100, 10, and 1 neurons), intending to predict\nwhether the nodes v1 and v2 will have w edges in\nthe future. After the training, the model computes\nthe probability for all 10 million evaluation exam-\nples. This list is sorted and the AUC is computed.\nG.\nM7: end-to-end ML (Transformers)\nThis model, which is detailed in [44], does not\nuse any handcrafted features but learns them in\na completely unsupervised manner.\nTo do so, we\nextract various snapshots of the adjacency matrix\nthrough time, capturing graphs in the form of At\nfor t = 1994, . . . , 2019.\nWe then embed each of\nthese graphs into 128-dimensional Euclidean space\nvia Node2vec [45, 46]. For each node u in the se-\nmantic graph, we extract diﬀerent 128-dimensional\nvector embeddings nu(A1994), . . . , nu(A2019).\nTransformers have performed extremely well in\nnatural language processing tasks [47], thus we ap-\nply them to learn the dynamics of the embedding\nvectors.\nWe pre-train a transformer to help clas-\nsify node pairs.\nFor the transformer, the encoder\nand decoder had 6 layers each; we used 128 as the\nembedding dimension, 2048 as the feedforward di-\nmension and 8-headed attention. This transformer\nacts as our feature extractor. Once we pre-train our\ntransformer, we add a 2-layer ReLU network with\nhidden dimension 128 as a classiﬁer on top.\nH.\nM8: end-to-end ML (auto node embedding)\nThe most immediate way one can apply machine\nlearning to this problem is by automating the detec-\ntion of features. Quite simply, the baseline solution\nM6 is modiﬁed such that instead of 15 hand-crafted\nfeatures, the neural network is instead trained on\nfeatures extracted from a graph embedding. In our\napproach, we use the ProNE embedding [48], which\nis based on sparse matrix factorizations modulated\nby the higher-order Cheeger inequality [49], as well\nas Node2Vec [45]. We use the implementations pro-\nvided in the nodevectors Python package [50].\nThe embeddings learn a 32-dimensional represen-\ntation for each node; hence, each edge representa-\ntion is normalized to a single point in [0, 1]64, and\nthe concatenated features are the input of a neu-\nral network with two hidden layers of size 1000 and\n30, respectively. Similarly to M6, the model is then\ntasked with computing the probability for the eval-\nuation examples, which lets us determine the ROC.\n9\nV.\nEXTENSIONS AND FUTURE WORK\nCreating an AI that can suggest research topics\nto human scientists is highly ambitious and chal-\nlenging. The present work of link prediction for a\ntemporal network to draw connections between ex-\nisting concepts is only the ﬁrst step. We point out\nseveral extensions and future works that are directly\nrelevant to the overarching goal of AI for AI.\nHigh-quality predictions without feature\nengineering – Surprisingly, given a graph with al-\nready extracted concepts as nodes and edges plotting\nthe time evolution of joint appearance of these con-\ncepts in publications, the most powerful methods\nall used carefully hand-crafted features. It will be\ninteresting to see whether end-to-end deep learning\nmethods can solve tasks without feature engineering.\nFully automated concept extraction – The\nconcept list at the moment is created by a purely sta-\ntistical text analysis using RAKE. The suggestions\nby RAKE are then manually inspected and phrases\nthat do not correspond to a concept are removed.\nWhile this process can be partially automated (as\nRAKE often makes the same mistakes which can\nbe captured automatically), it is not a scalable pro-\ncess if one wants to create concept lists for the much\nlarger corpus of science and engineering. A fully au-\ntomated natural language processing algorithm that\ncan extract meaningful concepts with minimal mis-\ntakes would be extremely useful.\nGeneration of new concepts – Here we pre-\ndict the emergence of links between two known con-\ncepts. One important question is whether an AI al-\ngorithm can compose words and generate new con-\ncepts. Diﬀerent from the current work that is mostly\nsupervised, the generation of new concepts is unsu-\npervised, hence more diﬃcult. One approach to ad-\ndress this question has been presented in [51, 52].\nThere the authors can detect clusters of concepts\nwith speciﬁc dynamics that indicate the formation\nof a new concept. It will be interesting to see how\nsuch emerging concepts can be incorporated into the\ncurrent framework and used for suggestions for new\nresearch topics.\nSemantic information beyond concept pairs\n– At the moment, every article’s abstract and title\nare compressed into several links between concept\npairs. This procedure does not represent all infor-\nmation in the article’s abstract (let alone, the ar-\nticle itself). The more information one can extract\nfrom the article, the more meaningful the predictions\nand suggestions will be. Extending the representa-\ntion of the semantic network to more complex data\nstructures, such as hypergraphs [53] are likely to be\ncomputationally more demanding but could signif-\nicantly improve the prediction qualities.\nIt might\nbe also possible to ﬁnd some ways to decrease the\ncomplexity of the analysis using clever tricks. For\nexample, the authors in [54] showed that the maxi-\nmum node and hyperedge cover problem, two com-\nputational NP-hard problems, can be solved in poly-\nnomial time for most of the real-world hypergraphs\ntested. Whether such tricks exist for hyperlink pre-\ndiction is still an open problem. The inclusion of so-\nciological factors, such as the status of the involved\nresearchers and their aﬃliations might help in pre-\ndiction tasks.\nPredictions of scientiﬁc success – The predic-\ntion of a new link between nodes in the semantic\nnetwork means that we predict which concepts sci-\nentists will study for the ﬁrst time in the future. This\nprediction however does not say anything about the\npotential importance and impact of the new connec-\ntion. As a tool for high-quality suggestions, we need\nto introduce the prediction of a metric-of-success, for\nexample, estimated citation numbers of the new link\nor the rate of citation growth over time. This exten-\nsion seems reasonable given that modelling and pre-\ndictions of citation information in citation networks\n(where nodes are papers) is a prominent area of re-\nsearch within the science of science [55, 56]. Adapt-\ning these techniques to semantic networks will be an\ninteresting future research direction.\nAnomaly detections – In a way, predicting the\nmost likely new connection between concepts does\nnot necessarily directly coincide with the goal of sug-\ngestions of new surprising research directions. After\nall, those links are predictable, thus potentially not\nsurprising by themselves. While we believe that this\ntype of prediction can still be a very useful contribu-\ntion for suggestions, there is another way to more di-\nrectly ﬁnd surprising combinations, namely by ﬁnd-\ning anomalies in the semantic networks. Those are\npotential links that have extreme properties in some\nmetrics. There are powerful deep learning methods\nfor anomaly detection [57, 58] and their application\nin the semantic network presented here might be\nvery interesting.\nIn fact, while scientists tend to\nstudy topics in which they are already directly in-\nvolved [2, 3], often higher scientiﬁc impact results\nfrom the unexpected combination of more distant\ndomains [10], which foster the search for those sur-\nprising and impactful associations.\nEnd-to-end formulation – As outlined above,\nwe necessarily decomposed our goal of extracting\nknowledge from the scientiﬁc literature into two sub-\ntasks:\nextracting concepts and building and pre-\ndicting the evolution of a semantic network result-\ning from those concepts.\nThis stands in contrast\nto the dominant paradigm in deep learning that\nemerged over the last decade of so-called ‘end-to-\nend’ training based on early spectacular successes\n10\n[59–62].\nIn this paradigm, problems are not bro-\nken into sub-problems but solved directly using deep\ndiﬀerentiable architecture components trained via\nback-propagation [63, 64]. If such an ‘end-to-end’\nsolution approach to our goal could be achieved it\nwould be interesting to see whether it could repli-\ncate the success this deep learning paradigm had in\nother areas.\nHuman level machine comprehension – One\nof the deﬁning goals of the Dartmouth Summer Re-\nsearch Project on Artiﬁcial Intelligence in 1956 was\nthe following: ‘An attempt will be made to ﬁnd how\nto make machines use language, form abstractions\nand concepts, solve kinds of problems now reserved\nfor humans, and improve themselves.’\n[65].\nSuch\nan algorithm would be expected to handle an evo-\nlution in concept denotations due to new insights\n(i.e. the emergence of the term ‘Gibbs entropy’ to\ndistinguish Boltzmann’s original concept of thermo-\ndynamical entropy as opposed to seeing it in the light\nof the more general emergent ‘Shannon entropy’ or\n‘von Neumann Entropy’) or due to disputed original-\nity (i.e. Bolai-Lobatchevskian Geometry and Hyper-\nbolic Geometry are the same concept). An algorithm\nwith such natural language understanding capabili-\nties would thus be extremely useful to get closer to\nour goal. Although large language models and other\nmultimodally trained language models like CLIP [66]\nor CLOOB [67] have achieved outstanding results re-\ncently, it is an open question how much statistically\ntrained natural language models alone could even-\ntually form concepts and abstractions on a human\nlevel [68, 69].\nVI.\nCONCLUSION\nHere we present a new AI benchmark for link\nprediction in exponentially growing semantic net-\nworks. Several of the solutions have been collected\nin the IEEE BigData Competition Science4Cast in\nfall 2021, and generalized to the mode diverse tasks\npresented here. The goal was to boost the capabil-\nities of predicting future research directions in the\nﬁeld of AI itself, which grows enormous over the\ndecade. This ability might be an important part of\na tool that gives personalized research suggestions\nto human scientists in the future. We ﬁnd, rather\nsurprisingly, that the prediction of strong new links\n(those that are formed three or more times) can be\npredicted with extremely high quality (AUC beyond\n99%). It will be interesting to investigate this quasi-\ndeterministic pattern in AI research in more de-\ntail. The best methods used a clever combination of\nhand-crafted features and machine learning. It will\nbe interesting whether pure learning methods, with-\nout hand-crafted features, will achieve high-quality\nresults in the future. We also point out a number\nof open problems towards the goal of practical, per-\nsonalized, interdisciplinary AI-based suggestions for\nnew impactful research direction – which we believe\ncould become a disruptive tool in the future.\nAPPENDIX\nA.\nModel availability\nAll of the models described above can be found on\nGitHub. M1, M2, M3, M4, M5, M6, M7, M8.\nB.\nDetails on M9\nThe\nsolution\nM9\nwas\nnot\npart\nof\nthe\nScience4Cast\ncompetition\nand\ntherefore\nnot\ndescribed in the corresponding proceedings, thus we\nwant to add more details. We compare the ProNE\nembedding to Node2Vec, which is also commonly\nused for graph embedding problems. The algorithm\nmaps each node of the network to a point in 32-\ndimensional space based on a biased random walk\nprocedure, which is fundamentally parameterized\nby two variables—p, the “return parameter”, and\nq, the “in-out parameter”.\nThe return parameter\ndetermines the frequency of backtracking in the\nrandom walk, while the in-out parameter deter-\nmines whether to bias the exploration to nearby\nnodes or distant nodes. Notably, these parameters\nsigniﬁcantly aﬀect how the network is encoded—for\ninstance,\nin\nthe\nBlogCatalog\ndataset,\noptimal\nparameters were p = 0.25, q = 0.25, whereas for\nthe Wikipedia graph, they were p = 4, q = 0.5\n[45].\nIn initial experiments, we used the default\np = q = 1 for a 64-dimensional encoding, before\nfeeding it into the same neural network as for\nthe ProNE experiment.\nThe higher variance in\nNode2Vec-based predictions likely has to do with\nthe method’s signiﬁcant sensitivity to its hyper-\nparameters.\nWhile ProNE is clearly better suited\nfor a general multi-dataset link prediction problem,\nNode2Vec’s\nparameter\nsensitivity\nmay\nhelp\nus\nidentify what features of the network are most\nimportant for predicting its temporal evolution.\nC.\nConsideration for Model M6\nIn this manuscript, a modiﬁcation was performed\nin relation to the original formulation of the method\n[42]: two of the original features, average neighbor\ndegree and clustering coeﬃcient, were infeasible to\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing**"
      ],
      "metadata": {
        "id": "vmIGzVLk-dt4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary packages\n",
        "\n",
        "import nltk\n",
        "from string import punctuation\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import string\n",
        "import re\n",
        "nltk.download(\"stopwords\")\n",
        "stop_words = stopwords.words('english')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWw09aedRH7-",
        "outputId": "25c6132e-8ddb-4975-d7bf-76a72b13020e",
        "execution": {
          "iopub.status.busy": "2023-10-23T22:10:11.097886Z",
          "iopub.execute_input": "2023-10-23T22:10:11.098695Z",
          "iopub.status.idle": "2023-10-23T22:10:12.611878Z",
          "shell.execute_reply.started": "2023-10-23T22:10:11.098661Z",
          "shell.execute_reply": "2023-10-23T22:10:12.610994Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdsE_btUsVXS",
        "outputId": "1f4bbbcc-9aea-4ee2-f8bd-16e6f09a8a38",
        "execution": {
          "iopub.status.busy": "2023-10-23T22:10:12.613038Z",
          "iopub.execute_input": "2023-10-23T22:10:12.613811Z",
          "iopub.status.idle": "2023-10-23T22:10:12.638187Z",
          "shell.execute_reply.started": "2023-10-23T22:10:12.613779Z",
          "shell.execute_reply": "2023-10-23T22:10:12.637330Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /usr/share/nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n",
          "output_type": "stream"
        },
        {
          "execution_count": 6,
          "output_type": "execute_result",
          "data": {
            "text/plain": "True"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This script preprocesses text data in a DataFrame (df) by removing tables, formulas, emails, URLs, converting to lowercase, removing special characters, single alphabets, numbers, punctuation, and extra spaces. It uses NLTK for text processing and regular expressions for pattern matching."
      ],
      "metadata": {
        "id": "4hNeaVUx_OY1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "\n",
        "# Downloading the 'punkt' tokenizer data\n",
        "nltk.download('punkt')\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Sentence Tokenization\n",
        "    sentences = sent_tokenize(text)\n",
        "\n",
        "    # Initializing an empty list to store preprocessed sentences\n",
        "    preprocessed_sentences = []\n",
        "\n",
        "    for sentence in sentences:\n",
        "\n",
        "        # Using regular expressions to remove tables and formulas (customize as needed)\n",
        "        table_pattern = r\"(?i)(?:Table|Tab\\.|Fig\\.)\\s+\\d+\\s*[:\\s-]*\\s*(.*?)\\s*(?=(?:Table|Tab\\.|Fig\\.|\\n|\\Z))\"\n",
        "        sentence = re.sub(table_pattern, \"\", sentence)\n",
        "\n",
        "        formula_pattern = r\"(\\$\\$[\\s\\S]*?\\$\\$|\\$[\\s\\S]*?\\$)\"\n",
        "        sentence = re.sub(formula_pattern, \"\", sentence)\n",
        "\n",
        "        # Removing E-mails\n",
        "        email_pattern = r'\\S+@\\S+\\.\\S+'\n",
        "        sentence = re.sub(email_pattern, '', sentence)\n",
        "\n",
        "        # Removing Urls\n",
        "        url_pattern = r'https?://\\S+|www\\.\\S+'\n",
        "        sentence = re.sub(url_pattern, '', sentence)\n",
        "\n",
        "        # Lowercasing\n",
        "        sentence = sentence.lower()\n",
        "\n",
        "        # Removing Special Characters\n",
        "        pattern = r'[^\\w\\s]'\n",
        "        sentence = re.sub(pattern, ' ', sentence)\n",
        "\n",
        "        # Removing single alphabets\n",
        "        sentence = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', sentence)\n",
        "\n",
        "        # Removing Numbers\n",
        "        sentence = re.sub(r'\\d+', '', sentence)\n",
        "\n",
        "        # Removing Punctuations\n",
        "        sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "        # Removing Extra Spaces\n",
        "        sentence = \" \".join(sentence.split())\n",
        "\n",
        "        # Appending the preprocessed sentence to the list\n",
        "        preprocessed_sentences.append(sentence)\n",
        "\n",
        "    # Joining the preprocessed sentences back into a single string with a space as delimiter\n",
        "    preprocessed_text = '. '.join(preprocessed_sentences)\n",
        "\n",
        "    return preprocessed_text\n",
        "\n",
        "# Apply the preprocessing function to the \"Text Data\" column using a lambda function\n",
        "df['source'] = df['source'].apply(lambda x: preprocess_text(x))\n",
        "\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "gSCxS3MLRH7-",
        "outputId": "afb4582e-7128-4c1b-a6a8-6a2e1ef448a1",
        "execution": {
          "iopub.status.busy": "2023-10-23T22:10:12.639461Z",
          "iopub.execute_input": "2023-10-23T22:10:12.639997Z",
          "iopub.status.idle": "2023-10-23T22:10:21.532446Z",
          "shell.execute_reply.started": "2023-10-23T22:10:12.639965Z",
          "shell.execute_reply": "2023-10-23T22:10:21.531236Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n",
          "output_type": "stream"
        },
        {
          "execution_count": 7,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                   Research_Paper_Name  \\\n0                                       2210.00881.pdf   \n1                                   TSP_CSSE_45181.pdf   \n2                             electronics-11-00325.pdf   \n3    Performance_of_Deep-Learning_Solutions_on_Lung...   \n4                                    9789392995101.pdf   \n..                                                 ...   \n341                              ASAfilippi_p_558s.pdf   \n342                               25894-50878-1-PB.pdf   \n343           Women_Empowerment_in_Bangladesh_NGOS.pdf   \n344                           diagnostics-12-00203.pdf   \n345                       20220122011404pmWEB19034.pdf   \n\n                                                source  \n0    predicting the future of ai with ai high quali...  \n1    insider attack detection using deep belief neu...  \n2    electronics of artiﬁcial intelligence systems ...  \n3    life of effective in reducing lung cancer mort...  \n4    keep your dreams alive. understand to achieve ...  \n..                                                 ...  \n341  detecting causes of spatial variation in crop ...  \n342  int elec comp eng issn computed tomography sca...  \n343  nu journal of humanities social sciences busin...  \n344  diagnostics of alt are the enzymes from liver ...  \n345  webology volume number january application of ...  \n\n[346 rows x 2 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Research_Paper_Name</th>\n      <th>source</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2210.00881.pdf</td>\n      <td>predicting the future of ai with ai high quali...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TSP_CSSE_45181.pdf</td>\n      <td>insider attack detection using deep belief neu...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>electronics-11-00325.pdf</td>\n      <td>electronics of artiﬁcial intelligence systems ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Performance_of_Deep-Learning_Solutions_on_Lung...</td>\n      <td>life of effective in reducing lung cancer mort...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9789392995101.pdf</td>\n      <td>keep your dreams alive. understand to achieve ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>341</th>\n      <td>ASAfilippi_p_558s.pdf</td>\n      <td>detecting causes of spatial variation in crop ...</td>\n    </tr>\n    <tr>\n      <th>342</th>\n      <td>25894-50878-1-PB.pdf</td>\n      <td>int elec comp eng issn computed tomography sca...</td>\n    </tr>\n    <tr>\n      <th>343</th>\n      <td>Women_Empowerment_in_Bangladesh_NGOS.pdf</td>\n      <td>nu journal of humanities social sciences busin...</td>\n    </tr>\n    <tr>\n      <th>344</th>\n      <td>diagnostics-12-00203.pdf</td>\n      <td>diagnostics of alt are the enzymes from liver ...</td>\n    </tr>\n    <tr>\n      <th>345</th>\n      <td>20220122011404pmWEB19034.pdf</td>\n      <td>webology volume number january application of ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>346 rows × 2 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using lexrank algorithm for preparing dataset."
      ],
      "metadata": {
        "id": "qv9muZlF_qg0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lexrank"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-23T22:10:21.534231Z",
          "iopub.execute_input": "2023-10-23T22:10:21.534966Z",
          "iopub.status.idle": "2023-10-23T22:10:35.723169Z",
          "shell.execute_reply.started": "2023-10-23T22:10:21.534923Z",
          "shell.execute_reply": "2023-10-23T22:10:35.721936Z"
        },
        "trusted": true,
        "id": "7D1GF_le6wt5",
        "outputId": "70ec56c3-2d54-4980-8e3c-881c7b5bd288"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting lexrank\n  Downloading lexrank-0.1.0-py3-none-any.whl (69 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.8/69.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.10/site-packages (from lexrank) (1.23.5)\nRequirement already satisfied: path.py>=10.5 in /opt/conda/lib/python3.10/site-packages (from lexrank) (12.5.0)\nRequirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from lexrank) (0.19.3)\nRequirement already satisfied: regex>=2017.11.9 in /opt/conda/lib/python3.10/site-packages (from lexrank) (2023.6.3)\nRequirement already satisfied: scipy>=0.19.0 in /opt/conda/lib/python3.10/site-packages (from lexrank) (1.11.2)\nCollecting urlextract>=0.7 (from lexrank)\n  Downloading urlextract-1.8.0-py3-none-any.whl (21 kB)\nRequirement already satisfied: path in /opt/conda/lib/python3.10/site-packages (from path.py>=10.5->lexrank) (16.7.1)\nRequirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from urlextract>=0.7->lexrank) (3.4)\nCollecting uritools (from urlextract>=0.7->lexrank)\n  Downloading uritools-4.0.2-py3-none-any.whl (10 kB)\nRequirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from urlextract>=0.7->lexrank) (3.10.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from urlextract>=0.7->lexrank) (3.12.2)\nInstalling collected packages: uritools, urlextract, lexrank\nSuccessfully installed lexrank-0.1.0 uritools-4.0.2 urlextract-1.8.0\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This script performs extractive summarization on research papers using LexRank, spaCy for text processing, and multiprocessing for efficiency. The summary size can be adjusted as needed.**"
      ],
      "metadata": {
        "id": "0GMcza16_6nn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lexrank import LexRank\n",
        "import spacy\n",
        "import pandas as pd\n",
        "from multiprocessing import Pool\n",
        "\n",
        "# Increasing the max_length to accommodate longer texts\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Preprocess the text with spaCy and apply LexRank to each text\n",
        "def extractive_summarize_text(text, summary_size=2):\n",
        "    doc = nlp(text)\n",
        "    sentences = [sent.text for sent in doc.sents]\n",
        "    lxr = LexRank(sentences)\n",
        "    summary = lxr.get_summary(sentences, summary_size=summary_size)  # Adjust the summary size as needed\n",
        "\n",
        "    # Truncate the summary to the specified size\n",
        "    if len(summary) > summary_size:\n",
        "        summary = summary[:summary_size]\n",
        "\n",
        "    return \" \".join(summary) if summary and \"No informative summary available\" not in summary else \"\"\n",
        "\n",
        "def parallel_summarization(df_chunk):\n",
        "    df_chunk['target'] = df_chunk['source'].apply(lambda x: extractive_summarize_text(x, summary_size=2))\n",
        "    return df_chunk\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    # Defining the number of processes to use (we can adjust this as needed)\n",
        "    num_processes = os.cpu_count()\n",
        "\n",
        "    # Splits the DataFrame into chunks for parallel processing\n",
        "    chunk_size = len(df) // num_processes\n",
        "    df_chunks = [df[i:i + chunk_size] for i in range(0, len(df), chunk_size)]\n",
        "\n",
        "    # Creates a multiprocessing pool and apply summarization in parallel\n",
        "    with Pool(processes=num_processes) as pool:  # Use \"Pool\" from the multiprocessing module\n",
        "        df_list = pool.map(parallel_summarization, df_chunks)\n",
        "\n",
        "    # Concatenates the processed DataFrame chunks\n",
        "    df = pd.concat(df_list, ignore_index=True)\n",
        "\n",
        "    # Prints the DataFrame with the \"Summary\" column\n",
        "    print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "nLUvwp_nRH8B",
        "outputId": "727fb791-c4a4-4912-b047-9eb4163b0fb5",
        "execution": {
          "iopub.status.busy": "2023-10-23T22:10:35.725214Z",
          "iopub.execute_input": "2023-10-23T22:10:35.725714Z",
          "iopub.status.idle": "2023-10-23T22:14:54.568308Z",
          "shell.execute_reply.started": "2023-10-23T22:10:35.725666Z",
          "shell.execute_reply": "2023-10-23T22:14:54.566814Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "                                   Research_Paper_Name  \\\n0                                       2210.00881.pdf   \n1                                   TSP_CSSE_45181.pdf   \n2                             electronics-11-00325.pdf   \n3    Performance_of_Deep-Learning_Solutions_on_Lung...   \n4                                    9789392995101.pdf   \n..                                                 ...   \n341                              ASAfilippi_p_558s.pdf   \n342                               25894-50878-1-PB.pdf   \n343           Women_Empowerment_in_Bangladesh_NGOS.pdf   \n344                           diagnostics-12-00203.pdf   \n345                       20220122011404pmWEB19034.pdf   \n\n                                                source  \\\n0    predicting the future of ai with ai high quali...   \n1    insider attack detection using deep belief neu...   \n2    electronics of artiﬁcial intelligence systems ...   \n3    life of effective in reducing lung cancer mort...   \n4    keep your dreams alive. understand to achieve ...   \n..                                                 ...   \n341  detecting causes of spatial variation in crop ...   \n342  int elec comp eng issn computed tomography sca...   \n343  nu journal of humanities social sciences busin...   \n344  diagnostics of alt are the enzymes from liver ...   \n345  webology volume number january application of ...   \n\n                                                target  \n0    we point out several extensions and future wor...  \n1    the stream mining algorithm with decision grap...  \n2    in the literature we ﬁnd different works that ...  \n3    data sources and search strategy systematic li...  \n4    in an organization where human intelligence is...  \n..                                                 ...  \n341  introduction crop yields are affected by many ...  \n342  finally both kenny et al. and wabnitz et al. c...  \n343  whitmore conceived empowerment as an interacti...  \n344  shao et al. applied ultra performance liquid c...  \n345  introduction artificial intelligence ai is the...  \n\n[346 rows x 3 columns]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df['source'][4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXOa9k3eRH8B",
        "outputId": "9bfde9b0-1a2d-407d-f35e-6a7bb5440684",
        "execution": {
          "iopub.status.busy": "2023-10-23T22:14:54.574485Z",
          "iopub.execute_input": "2023-10-23T22:14:54.575278Z",
          "iopub.status.idle": "2023-10-23T22:14:54.582992Z",
          "shell.execute_reply.started": "2023-10-23T22:14:54.575238Z",
          "shell.execute_reply": "2023-10-23T22:14:54.582233Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 10,
          "output_type": "execute_result",
          "data": {
            "text/plain": "28711"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df['target'][4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3MRgepvRH8B",
        "outputId": "7192ade7-c18c-44ca-f502-c380de7c216c",
        "execution": {
          "iopub.status.busy": "2023-10-23T22:14:54.584371Z",
          "iopub.execute_input": "2023-10-23T22:14:54.584939Z",
          "iopub.status.idle": "2023-10-23T22:14:54.600254Z",
          "shell.execute_reply.started": "2023-10-23T22:14:54.584909Z",
          "shell.execute_reply": "2023-10-23T22:14:54.599025Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 11,
          "output_type": "execute_result",
          "data": {
            "text/plain": "453"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['source'][4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "BeiW4d93kLUw",
        "outputId": "a92ce769-4cf6-41d3-ed93-0f224588dfc8",
        "execution": {
          "iopub.status.busy": "2023-10-23T22:14:54.601547Z",
          "iopub.execute_input": "2023-10-23T22:14:54.601902Z",
          "iopub.status.idle": "2023-10-23T22:14:54.613543Z",
          "shell.execute_reply.started": "2023-10-23T22:14:54.601871Z",
          "shell.execute_reply": "2023-10-23T22:14:54.612323Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 12,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'keep your dreams alive. understand to achieve anything requires faith and belief in yourself vision hard work determination and dedication. remember all things are possible for those who believe. gail devers outcomes of best practices in classroom research edited by dr shanmuga sundari dr seng tong chong dr prabu published by ordine nuovo publication book title outcomes of best practices in classroom research editors dr shanmuga sundari department of computer science and engineering sri venkateswara college of engineering and technology chittoor india dr seng tong chong department of social science humanities college of energy economics and social sciences universiti tenaga nasional uniten malaysia dr prabu department of computer sciences central campus christ bangalore india book subject engineering and technology book category edited volume copy right editors first edition december book size b paper kg maplitho ns price rs published by ordine nuovo publication mail mobile. isbn assigned by raja ram mohan roy national agency for isbn new delhi india isbn isbn disclaimer the publisher and editors cannot be held responsible for errors or any consequences arising from the use of information in this book the views and opinions expressed herein are of the authors and do not necessarily reflect those of the publisher and editors. contents no title page no. artificial intelligence and its applications that are changing the world sneha agarwal artificial intelligence pillar of the modern society midhun path to immortality through cryonics soumyata binani aishwarya balajee navya tatiparthi artificial intelligence super power sanjana gamification of education karthik rajesh malavika menon goutham krishna artificial intelligence the inescapable ananya priyadarshini artificial intelligence in cyber defense technologies jayadev k kevin gladius the world of artificial intelligence shreya mangal evolution of the cosmos adrija chakraborthy parts of computerized reasoning theja advancement of cooling technology in batteries of electric vehicles satyam gautam guarang salunke kushal shah artificial intelligence an automated creation nandigam kamali haripriya lifi technology aditya ray aliasgar amir merchant riddhi dwivedi artificial intelligence is not matter of science fiction khushi teli artificial intelligence in education and machine learning ankit jain priyanshumourya burhan salaria knowledge on artificial intelligence reddi gowtham wireless power transmission technologies for wsns and charging of mobile devices animisha cs vl darshan ram konish bagchi process and progress of artificial intelligence brinda gesture recognition for automation soham korgaonkar dhavalvijapuri tanmay kulkarni artificial intelligence the th new wonder of the world sayan sooraj detecting tumors in human body by the means of light kandula sai alekhya hezal anish doshi artificial intelligence r. amithese suganth cloud computing security tanniru prabhu eshwar allen bastian artificial intelligence the future of learning somannagari rishikesava reddy cyber hacking harshith reddy parreddy varshith reddy vuyyuru ram sai manyala why and how artificial intelligence is the new black ishanvi. kotha improvement in design of engines to reduce emissions in aircarft and increase fuel efficiency shashank shukla harsh vardhan singh lakshya mishra artificial intelligence and future of humanity a. sundhar integrating technology in agriculture prateek garg madeshyerukola ashwin toms artificial intelligence the future hamza khan analysis of the feasibility of small modular reactors akshat kasana himanshu burde sameer ranjan artificial intelligence sanskar jotwani cyber crime and need of cyber camandos shivam kumar singh artificial intelligence what is it. rituraj mahato augmented reality an alternate living shrayanth ss narendharan rahul artificial intelligence revolutionary step towards life tanishq methi various aspects of artificial intelligence kande venkata ashutosh various aspects of artificial intelligence abhijai rajawat journey to known virtual world ai akshita kumari an idea of artificial intelligence meenakshi mattathil is artificial intelligence required. adithya navanitha krishnan artificial intelligence and it applications s. tharikesh artificial intelligence human friend or evil soumya maji artificial intelligence through dissection rohan sebastian artficial intelligence boon or curse. devanapally ashutosh artificial intelligence praveen artificial intelligence tushar modi artificial intelligence vinay kumar verma artificial intelligence akshat shrivastava glimpse on artificial intelligence satakshi porwal artificial intelligence in real life shivli gupta an insight into artificial intelligence h. mohamed arshad the world of ai kaushik tellakula the new future world driving force keerthana morden universe of artificial intelligence devansh tamakuwala artificial intelligence anu gowda artificial intelligence and the human brain titas raha tomorrows world ai maram srivardhani artificial intelligence raja jaiswal the past present and future of artificial intelligence vaibhav singh one step towards the new era artificial intelligence yash vishnu chopade outcomes of best practices in classroom research artificial intelligence and its applications that are changing the world sneha agarwal. tech computer science email id what is artificial intelligence. it is basically the science of developing smart machines in the form of different computer programs. it is related to making computer so intelligent that they can understand humans but it does not mean that they should also be biologically related to human. artificial intelligence is the ability of digital computers to solve problems that are associated with high thinking ability which cannot be solved by human beings at the present time. ai is field of computer science that allows us to create intelligent machines that behave like humans think like humans and make their own decisions. artificial intelligence is composed of two words artificial which defines artificial things and intelligence which expresses the ability to think for oneself so artificial intelligence is artificial thinking power. this field was founded on the idea that someday machines will be able to think that is they will be able to reproduce intellect and intelligence along with consciousness the functions that make us human. it may sound like science fiction or concept of new era but in fact there are references to them in myths as well as other text scriptures and artefacts. artificial intelligence is not just turning point in the field of research but also in the revolutionary industry and work as we know it today. with the ultimate goal of creating consciousness ai goes through different stages planning reasoning data analysis predicting outcomes and acting accordingly. artificial intelligence includes the use of statistics and probability as well as many mathematical tools neural networks and machine learning are mostly based on them. history of ai artificial intelligence ai missions start with dreams like all missions. people have long imagined machines with human capabilities automatic cars that move and the devices that work for it. human like machines are depicted in many stories and depicted in sculptures paintings and drawings. you may be familiar with many of them but let me mention few. homer iliad speaks of self propelled chairs known as tripods and gold carts built by hephaestus the lame blacksmith god to help him move. metamorphosis pygmalian sculpts an ivory statue of beautiful young girl galatea which venus brought to life. in george boole became the first person to describe formal language for logical reasoning. in alan turing gave theory to check software intelligence. according to his theory any software is considered intelligent if human being talking to it cannot predict whether he is talking to computer or person. this test was called the turing test. people realized that the intelligent machine is an idea whose time has come and it is not only this computer that presents vehicle with which such dream can be realized. there is constellation of events most notably the change from the dominant model the energy physicist concept to new model the cybernetics concept and has constant efforts to describe psychology and biological phenomena mathematically. because of these convergence points young associate professor of mathematics at dartmouth college named john mccarthy who had been fascinated by these questions for quite some time suggested for his friends that real isbn progress can be realized if only everyone is solving these problems. those three friends marvin minsky another young researcher were harvard junior fellows in mathematics and neuroscience nathaniel rochester director of information studies at the ibm research centre in poughkeepsie y and claude shannon then mathematician at bell laboratories who was heavily involved in the model transformation from energy to information agreed that perhaps it was it not bad idea and together with mccarthy submitted proposal to the rockefeller foundation for study of ten two month old men on artificial intelligence conducted in the summer of in dartmouth college in hanover new hampshire. research must be conducted on the basis of conjecture that any aspect of learning or any other characteristic of intelligence can in principle be described precisely so accurate that could bring machine to mimic. this is the first time the term artificial intelligence has been officially used. work going on in this area he has promoted the term and despite several other proposals and one number of grumbles artificial intelligence is still blocked. in addition others made short visits to talk about related work. among those visitors were alex bernstein then programmers from ibm in new york city were invited to talk about the chess program he was working on which would receive lot of the public then causing ibm people to fear that the idea of smart machines was so threatening that it would deter customers from buying computers. growth of ai artificial intelligence is growing rapidly as factor of competitiveness and is being used by large companies rapidly. it cannot be confined only to individual companies but also has high potential to contribute in national economy system. artificial intelligence ai is considered as the fourth industrial revolution. artificial intelligence with big data has changed all industries around the world. artificial intelligence refers to the simulation of human or animal intelligence in computer system thinking of it as an intelligent entity and programmed to mimic the behaviour of the intelligent entity. computer systems with programmed intelligence can solve variety of real world problems much more accurately and efficiently than deterministic and hard coded computer systems. ai plays an important role in solving problems in the business world as many problems in business and business analytics cannot be solved by the deterministic system. machine learning and deep learning subset of the realm of ai solves and optimizes many business issues such as marketing credit card fraud detection algorithmic trading customer service portfolio management product recommendation and many more. ai and big data revolutionized the business world. ai in healthcare appliances the experts observed that out of more than patients per day which can be very debilitating for people considering the amount of advice and information needed for people. unlike physicians ais are not episodic by number of patients hours of work and are redundant in duties. ai helps doctors assess how dangerous patient health is and then uses intelligence to not only develop quality of care but also observe and advise patients on the effects side effects of certain drugs. the global impact of ai is very challenging with high tech developed tools to improve decision making disease detection and management of diseases such as chronic diseases and acute diseases. doctors and other medical professionals use ai for more accurate diagnosis. in medicine ai uses arithmetic algorithms as well as human body data science to diagnose better than doctors can do. this gives professionals the ability for to take immediate action on illnesses that could become serious. health outcomes of best practices in classroom research systems need to be understood about the variety of systems that are heterogeneous distributed and common speak different languages integrate medical devices and are personalized by different entities respectively identified by people living in different contexts and aiming for different goals. analysis of tests rays ct scans records entry and different habitual obligations can all be achieved much quicker and with extra precision via way of means of robots. cardiology and radiology are regions where the quantity of records to bear in mind can be overwhelming and tedious. future cardiologists and radiologists ought to bear in mind only the maximum complicated cases for which human tracking are useful. ibm got here up with any other set of rules called medical sieve. it is bold long time period investigative project that targets to create the subsequent technology of cognitive assistants with analytical and reasoning competencies and variety of medical knowledge. medical sieve is certified to aid medical choice making in radiology and cardiology. the cognitive fitness assistant is that may test ray pictures for markers and discover complications quicker and greater reliably ai is nowadays been used in the orthognathic surgery as intra oral scanner software which helps in faster and more efficient acquisition. also the use of ai in d radiology improves the signal to noise ratio and gives higher quality image which eventually helps to lower the doses of radiations. artificial intelligence is being used in machines like echocardiograms mris ct scans etc to test screening results. it helps to measure the accurate working and analysis from the beginning till the end of the healing process. ai devices mainly divide into two main categories. the first category includes machine learning ml techniques that analyze structured data such as imaging genetics and ep data. in medical applications ml procedures attempt to group patient characteristics or infer probability of disease. the second category includes natural language processing nlp takes information from the unstructured data like medical journals to complete and enrich structured medical data. nlp procedures are used for converting text into machine readable structured data which can then be analyzed using ml techniques. ai in manufacturing and production smart technologies like internet of things cloud computing big data and cyber physical systems lead to the emergence of intelligent manufacturing as new version of smart manufacturing. modern production and logistics systems are supported by increasingly widespread and powerful computer networks. in these networks the constant ocean of data is generated by sensors machines systems smart devices and people. with increasing computing power this big data is being analyzed faster wider and deeper than ever before. these advancements have redefined the value of artificial intelligence ai technologies and ushered in new era known as industry or smart factory. advanced cognitive computing and deep learning methods have begun to find applications in manufacturing systems for automated visual inspection fault detection and maintenance. active efforts are being made to apply reinforcement learning methods to material handling and production planning systems. industries that hope to transform real time data into actionable decisions are looking for opportunities to integrate ai methods with traditional operations research approaches concepts and technologies internet of things iot as well as network physical systems. ai technologies could assist the production planner in choosing the best production process which not only reduces the cost of production but also increases the quality and efficiency of the production process. it also helps to build an intelligent system which automatically adapts the process parameters according to changing conditions. isbn intelligent method designing may be dynamic and sophisticated activity. method designing provides close description of manufacturability and needs for changing raw materials stock into finished product. intelligent method designing includes computer aided process planning capp and layout of facilities and locations. method designing is that interface between computer aided design cad and computer aided manufacturing cam. capp is important in achieving the final word goal of totally integrated factories within the future. the capp system contains an outsized quantity of data as well as rules for organization of machine operations and factual information concerning the shop. inventory management is additionally thought of during these sections as result of palmy inventory management is important to palmy producing and needs refined strategies for handling dynamical surroundings. the literature is choked with articles on freelance theoretical models of demand inventory however it lags behind these developments. ai will play very important role in serving to practitioners implement such models and conjointly overcome the issues related to large scale inventory management. ai in security and surveillance michael rogers the director of national security agency nsa said that the agency sees ai as the foundation to the future of cyber security. in december drda held head to head fight challenge between autonomous machines. each machine was capable of automatically finding and making use of cyber vulnerabilities in its opponents and at the same time mending its own vulnerabilities and protecting itself from external cyber attacks. as result of this tournament dod began the project voltron to develop such systems to scan and patch vulnerabilities in the s military. activities such as advanced persistent threat operations which are currently more labour intensive in the coming times may become largely automated and easily available on the black market with the increasing development in ai. the application of ai based techniques has great potential to boost the security and potency of data driven intelligent transportation systems its further as new services and rising of the internet of vehicles iov. this text discusses the sensible implementation of deep learning strategies to reinforce safety and security in very specific its scenarios such as railway crossings. this work presents the projected system named artificial intelligence based surveillance system for railway crossing traffic aissrct. it supports mixture of detection and classification strategies and specializes in numerous image processing inputs such as vehicle presence pedestrian presence vehicle chase rail barriers at level crossings scene railway signals and signal fire system. the system is meant to use properly positioned cameras to capture the complete crossing space at given intersection. by utilizing gpu accelerated image process and deep neural networks the system mechanically detects risky and dangerous things at railway crossings in real time. additionally camera modules send information to central server for additional process further as notification to interested parties like police emergency services and railway operators. in addition the system design uses privacy and security based practices deliberately to secure all communication interfaces shield personal information and increase everyone privacy e pedestrians and motorists. artificial intelligence in education intelligent tutoring systems its uses artificial intelligence technologies to stimulate individualized human learning and provides educational activities that best match the analytical needs of the learner. in addition to this it also provides targeted and timely feedbacks without the presence of any individual faculty. some its put learners in control of their own learning to help outcomes of best practices in classroom research students develop self regulation skills others use instructional strategies to extend learning so that learners are appropriately challenged and supported. for example buggy revolutionary system designed to teach basic addition and subtraction used model of possible misconceptions that learners could present among learn their procedure. this error library is in fact the system domain model used to diagnose any student errors so that appropriate tutoring can be provided. modern model driven adaptive systems can be much more flexible. they allow the rationale for all system decisions to be made unambiguously and understandable by humans and thus applicable to classroom instruction. over the past decade increasingly complex learner models pedagogies and domains have been introduced into many adaptive tutors to support personalized learning. for example the italklearn system designed to help young students learn fractions used learner model that included information about math knowledge cognitive needs status affective emotional state the feedback they receive and their reaction to those comments. intelligent tutoring systems its offers great flexibility in the presentation of material and has good ability to respond to the individual needs of the student. these systems achieve their intelligence by representing the decisions about how to teach particular student as well as gives information about the learner. this allows great diversity by changing the way system interacts with the student. squirrel famous company in china uses ai in education. for every course that the company offers the engineering team works with group of master teachers to break down the subject into the smallest possible conceptual pieces known as knowledge points. the purpose is to diagnose the student gap in understanding as accurately as possible. once knowledge points are established they are paired with video presentations notes edited examples and exercises. advantages of ai artificial intelligence ai applications are used to simulate human intelligence to solve problem or make decision. ai provides the benefits of permanence reliability and cost effectiveness while addressing uncertainty and speed in solving problem or making decision. ai has been used in fields as diverse as engineering economics linguistics law manufacturing and medicine and for wide range of modelling prediction and decision support applications regulation and control. one of the most promising applications of ai has been rigorously used on the internet as well as in search engines. in an organization where human intelligence is tied to particular person or to group of people ai applications can provide the permanence that knowledge is not lost as individuals or group members retire or are no longer available to the organization. the lifespan of knowledge encapsulated within an ai framework can be extended as long as the relevance of the problems and decision scenarios remains unchanged. ai also enables the development of learning capabilities that can be used to extend the life and relevance of applications. learning from real world successes and failures is an enabling trait of application tools. ai is called reinforcement learning and has the advantage that it increases the reliability of tools as they are used more in applications. ai already has many applications in the medical field such as online bookings of appointments for various doctors online check in at the medical centres digitization of medical records follow ups for booking and even vaccination reminders for children and pregnant women. it is also being used to give warnings of the side effects to the doctors when prescribing combination of several medicines. one of the great things about artificial intelligence is that it makes decision based on facts and not on emotions. it is much known fact that even after our best efforts human decisions are always adversely affected by the emotions. the area of robotics is often referred to as the sub area of ai that deals with perceptual and motor tasks. a robot is mechanical device that performs an automated task under the direct supervision of human being under predefined program or under set of common guidelines using artificial intelligence technology. today as clients become more sophisticated and knowledgeable they isbn prefer to make financial transitions with less human interactions. the technical field is much broader and has the potential to improve the overall efficiency of the financial system. one of the most popular tools is the smart contract computer program that can execute contract terms idelberger governatori riveret sartor. fully automated smart contracts can complement or completely replace common legal contracts. this is clear as smart contracts are becoming increasingly important in multiple industries such as healthcare real estate and securities. there are about possible uses for banking systems insurance management etc. disadvantages of ai artificial intelligence makes people lazy because applications automate most of the work. people tend to push themselves into these inventions which can weigh on future generations. since ai replaces the majority of repetitive tasks and other jobs with robots with less human intervention which can be significant problem in usage standards. every organization seeks to exchange the minimum number of skilled individuals with ai bots that can do the same job more efficiently. there is no doubt that machines are much better when it comes to efficiency but they cannot replace the human connections that make up the team. machines cannot bond with humans which is an important attribute when it comes to team management. machines can only perform the tasks for which they were designed or programmed to attempt anything they tend to fail or produce irrelevant outputs can be context of serious scene. the high cost of developing ai based applications can mean that the first impulse comes from the private sector. needless to say businesses can earn revenue from areas with large profit pools without having to deal with socially relevant issues such as equal access. given all the possible events in the real world big data learning takes long time so ai is usually limited to one frame or type of problem. for example if we limit the algorithm to only applying to chess image recognition or speech we can only expect specific results. however in the real world there are infinite possibilities that we have to anticipate when trying to handle all phenomena so database overload will make the search time infinite. one of the ethical dilemmas that can be identified is the issue of unemployment. the development of specialized machines has led to the fact that more and more workplaces have been replaced from the industrial revolution to the present. starting with less skilled and repetitive task that requires little reasoning to perform to even surgical precision and more complex tasks are being replaced by economically more efficient machines. computers cannot handle unexpected situations. for students the learning environment is diverse and constantly changing. due to the limitations of computer artificial intelligence computer technology does not respond to students unexpected learning problems as teachers do and also does not immediately answer students questions. conclusion from the above discussion we can see that artificial intelligence technologies make human life easier and that by future artificial intelligence technologies may bring greater competitive advantage. in this way artificial intelligence can make great discoveries and breakthroughs for mankind thanks to its many capabilities. most of the ai systems are capable of learning which allows people to improve their performance over time. evidence shows that ai can bring real added value to our lives. ai works on the basis of accessing huge amounts of information processing it analyzing it and according to its operational algorithms performing tasks to solve certain problems. finally during this research we went through ai definitions brief history growth of ai ai in healthcare appliances ai in security and surveillance ai in education some advantages and disadvantages of ai. this is not the top of ai there is more to learn who knows what ai can do for us in the future maybe that will be whole robotics company'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['target'][4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "NrNvnDweRH8B",
        "outputId": "e84a2a41-c933-41ef-f71d-6460c965daae",
        "execution": {
          "iopub.status.busy": "2023-10-23T22:14:54.614882Z",
          "iopub.execute_input": "2023-10-23T22:14:54.615206Z",
          "iopub.status.idle": "2023-10-23T22:14:54.632046Z",
          "shell.execute_reply.started": "2023-10-23T22:14:54.615180Z",
          "shell.execute_reply": "2023-10-23T22:14:54.630759Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 13,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'in an organization where human intelligence is tied to particular person or to group of people ai applications can provide the permanence that knowledge is not lost as individuals or group members retire or are no longer available to the organization. ai helps doctors assess how dangerous patient health is and then uses intelligence to not only develop quality of care but also observe and advise patients on the effects side effects of certain drugs.'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"output_csv(clean).csv\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-23T22:14:54.633620Z",
          "iopub.execute_input": "2023-10-23T22:14:54.633952Z",
          "iopub.status.idle": "2023-10-23T22:14:55.037426Z",
          "shell.execute_reply.started": "2023-10-23T22:14:54.633924Z",
          "shell.execute_reply": "2023-10-23T22:14:55.036342Z"
        },
        "trusted": true,
        "id": "bL-qiDMu6wt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Building"
      ],
      "metadata": {
        "id": "vtBQpALiRH8B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "T5 (Text-To-Text Transfer Transformer) is a versatile transformer-based language model developed by Google. Unlike traditional models that are designed for specific NLP tasks, T5 treats all tasks as text-to-text tasks. It takes both input and output as text, allowing it to perform a wide range of tasks like translation, summarization"
      ],
      "metadata": {
        "id": "Aa4vTXrJAPdR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using t5 model"
      ],
      "metadata": {
        "id": "16HDt6ci6wt7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge\n",
        "!pip install simplet5"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-01T15:32:00.752267Z",
          "iopub.execute_input": "2023-11-01T15:32:00.752902Z",
          "iopub.status.idle": "2023-11-01T15:32:42.063991Z",
          "shell.execute_reply.started": "2023-11-01T15:32:00.752869Z",
          "shell.execute_reply": "2023-11-01T15:32:42.063019Z"
        },
        "trusted": true,
        "id": "XE8I4f1L6wt7",
        "outputId": "7fbd4b95-6832-4272-cfb6-e34810fbbf77"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting rouge\n  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from rouge) (1.16.0)\nInstalling collected packages: rouge\nSuccessfully installed rouge-1.0.1\nCollecting simplet5\n  Downloading simplet5-0.1.4.tar.gz (7.3 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from simplet5) (1.23.5)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from simplet5) (2.0.2)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from simplet5) (0.1.99)\nRequirement already satisfied: torch!=1.8.0,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from simplet5) (2.0.0)\nCollecting transformers==4.16.2 (from simplet5)\n  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting pytorch-lightning==1.5.10 (from simplet5)\n  Downloading pytorch_lightning-1.5.10-py3-none-any.whl (527 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.7/527.7 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: future>=0.17.1 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning==1.5.10->simplet5) (0.18.3)\nRequirement already satisfied: tqdm>=4.41.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning==1.5.10->simplet5) (4.66.1)\nRequirement already satisfied: PyYAML>=5.1 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning==1.5.10->simplet5) (6.0)\nRequirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning==1.5.10->simplet5) (2023.9.0)\nRequirement already satisfied: tensorboard>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning==1.5.10->simplet5) (2.12.3)\nRequirement already satisfied: torchmetrics>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning==1.5.10->simplet5) (1.1.1)\nCollecting pyDeprecate==0.3.1 (from pytorch-lightning==1.5.10->simplet5)\n  Downloading pyDeprecate-0.3.1-py3-none-any.whl (10 kB)\nRequirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning==1.5.10->simplet5) (21.3)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning==1.5.10->simplet5) (4.6.3)\nCollecting setuptools==59.5.0 (from pytorch-lightning==1.5.10->simplet5)\n  Downloading setuptools-59.5.0-py3-none-any.whl (952 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m952.4/952.4 kB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.16.2->simplet5) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.16.2->simplet5) (0.16.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.16.2->simplet5) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.16.2->simplet5) (2.31.0)\nCollecting sacremoses (from transformers==4.16.2->simplet5)\n  Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.16.2->simplet5) (0.13.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch!=1.8.0,>=1.7.0->simplet5) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch!=1.8.0,>=1.7.0->simplet5) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch!=1.8.0,>=1.7.0->simplet5) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->simplet5) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->simplet5) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->simplet5) (2023.3)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10->simplet5) (3.8.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=17.0->pytorch-lightning==1.5.10->simplet5) (3.0.9)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->simplet5) (1.16.0)\nRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.10->simplet5) (1.4.0)\nRequirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.10->simplet5) (1.51.1)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.10->simplet5) (2.20.0)\nRequirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.10->simplet5) (1.0.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.10->simplet5) (3.4.3)\nRequirement already satisfied: protobuf>=3.19.6 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.10->simplet5) (3.20.3)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.10->simplet5) (0.7.1)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.10->simplet5) (2.3.7)\nRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.10->simplet5) (0.40.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.16.2->simplet5) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.16.2->simplet5) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.16.2->simplet5) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.16.2->simplet5) (2023.7.22)\nRequirement already satisfied: lightning-utilities>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics>=0.4.1->pytorch-lightning==1.5.10->simplet5) (0.9.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch!=1.8.0,>=1.7.0->simplet5) (2.1.3)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from sacremoses->transformers==4.16.2->simplet5) (8.1.7)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from sacremoses->transformers==4.16.2->simplet5) (1.3.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch!=1.8.0,>=1.7.0->simplet5) (1.3.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10->simplet5) (23.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10->simplet5) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10->simplet5) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10->simplet5) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10->simplet5) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10->simplet5) (1.3.1)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.5.10->simplet5) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.5.10->simplet5) (0.2.7)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.5.10->simplet5) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.2.0->pytorch-lightning==1.5.10->simplet5) (1.3.1)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.5.10->simplet5) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.2.0->pytorch-lightning==1.5.10->simplet5) (3.2.2)\nBuilding wheels for collected packages: simplet5\n  Building wheel for simplet5 (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for simplet5: filename=simplet5-0.1.4-py3-none-any.whl size=6857 sha256=b15864987fda6367a213c748cbf85d8d0617bb246dc9c2681c62f7db326d8855\n  Stored in directory: /root/.cache/pip/wheels/b4/7d/af/743765400878438a7593f13f89fdf4004dcde0f2a8e6cb6684\nSuccessfully built simplet5\nInstalling collected packages: setuptools, sacremoses, pyDeprecate, transformers, pytorch-lightning, simplet5\n  Attempting uninstall: setuptools\n    Found existing installation: setuptools 68.0.0\n    Uninstalling setuptools-68.0.0:\n      Successfully uninstalled setuptools-68.0.0\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.33.0\n    Uninstalling transformers-4.33.0:\n      Successfully uninstalled transformers-4.33.0\n  Attempting uninstall: pytorch-lightning\n    Found existing installation: pytorch-lightning 2.0.8\n    Uninstalling pytorch-lightning-2.0.8:\n      Successfully uninstalled pytorch-lightning-2.0.8\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nconda 23.7.3 requires setuptools>=60.0.0, but you have setuptools 59.5.0 which is incompatible.\nopentelemetry-api 1.18.0 requires importlib-metadata~=6.0.0, but you have importlib-metadata 6.7.0 which is incompatible.\npymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.23.5 which is incompatible.\npymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.11.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed pyDeprecate-0.3.1 pytorch-lightning-1.5.10 sacremoses-0.1.1 setuptools-59.5.0 simplet5-0.1.4 transformers-4.16.2\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Opening the JSON file for reading\n",
        "data = pd.read_csv(\"/kaggle/input/recleaned-csv/output_csv(clean).csv\")\n",
        "df = pd.DataFrame(data)\n",
        "df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-01T15:32:53.262223Z",
          "iopub.execute_input": "2023-11-01T15:32:53.262685Z",
          "iopub.status.idle": "2023-11-01T15:32:53.805879Z",
          "shell.execute_reply.started": "2023-11-01T15:32:53.262637Z",
          "shell.execute_reply": "2023-11-01T15:32:53.804916Z"
        },
        "trusted": true,
        "id": "pvDqa4bh6wt7",
        "outputId": "c2ec3102-104a-4e0a-9614-d236277a7f7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 3,
          "output_type": "execute_result",
          "data": {
            "text/plain": "     Unnamed: 0                                Research_Paper_Name  \\\n0             0                                     2210.00881.pdf   \n1             1                                 TSP_CSSE_45181.pdf   \n2             2                           electronics-11-00325.pdf   \n3             3  Performance_of_Deep-Learning_Solutions_on_Lung...   \n4             4                                  9789392995101.pdf   \n..          ...                                                ...   \n341         341                              ASAfilippi_p_558s.pdf   \n342         342                               25894-50878-1-PB.pdf   \n343         343           Women_Empowerment_in_Bangladesh_NGOS.pdf   \n344         344                           diagnostics-12-00203.pdf   \n345         345                       20220122011404pmWEB19034.pdf   \n\n                                                source  \\\n0    predicting the future of ai with ai high quali...   \n1    insider attack detection using deep belief neu...   \n2    electronics of artiﬁcial intelligence systems ...   \n3    life of effective in reducing lung cancer mort...   \n4    keep your dreams alive. understand to achieve ...   \n..                                                 ...   \n341  detecting causes of spatial variation in crop ...   \n342  int elec comp eng issn computed tomography sca...   \n343  nu journal of humanities social sciences busin...   \n344  diagnostics of alt are the enzymes from liver ...   \n345  webology volume number january application of ...   \n\n                                                target  \n0    we point out several extensions and future wor...  \n1    the stream mining algorithm with decision grap...  \n2    in the literature we ﬁnd different works that ...  \n3    data sources and search strategy systematic li...  \n4    in an organization where human intelligence is...  \n..                                                 ...  \n341  introduction crop yields are affected by many ...  \n342  finally both kenny et al. and wabnitz et al. c...  \n343  whitmore conceived empowerment as an interacti...  \n344  shao et al. applied ultra performance liquid c...  \n345  introduction artificial intelligence ai is the...  \n\n[346 rows x 4 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Research_Paper_Name</th>\n      <th>source</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2210.00881.pdf</td>\n      <td>predicting the future of ai with ai high quali...</td>\n      <td>we point out several extensions and future wor...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>TSP_CSSE_45181.pdf</td>\n      <td>insider attack detection using deep belief neu...</td>\n      <td>the stream mining algorithm with decision grap...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>electronics-11-00325.pdf</td>\n      <td>electronics of artiﬁcial intelligence systems ...</td>\n      <td>in the literature we ﬁnd different works that ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Performance_of_Deep-Learning_Solutions_on_Lung...</td>\n      <td>life of effective in reducing lung cancer mort...</td>\n      <td>data sources and search strategy systematic li...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>9789392995101.pdf</td>\n      <td>keep your dreams alive. understand to achieve ...</td>\n      <td>in an organization where human intelligence is...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>341</th>\n      <td>341</td>\n      <td>ASAfilippi_p_558s.pdf</td>\n      <td>detecting causes of spatial variation in crop ...</td>\n      <td>introduction crop yields are affected by many ...</td>\n    </tr>\n    <tr>\n      <th>342</th>\n      <td>342</td>\n      <td>25894-50878-1-PB.pdf</td>\n      <td>int elec comp eng issn computed tomography sca...</td>\n      <td>finally both kenny et al. and wabnitz et al. c...</td>\n    </tr>\n    <tr>\n      <th>343</th>\n      <td>343</td>\n      <td>Women_Empowerment_in_Bangladesh_NGOS.pdf</td>\n      <td>nu journal of humanities social sciences busin...</td>\n      <td>whitmore conceived empowerment as an interacti...</td>\n    </tr>\n    <tr>\n      <th>344</th>\n      <td>344</td>\n      <td>diagnostics-12-00203.pdf</td>\n      <td>diagnostics of alt are the enzymes from liver ...</td>\n      <td>shao et al. applied ultra performance liquid c...</td>\n    </tr>\n    <tr>\n      <th>345</th>\n      <td>345</td>\n      <td>20220122011404pmWEB19034.pdf</td>\n      <td>webology volume number january application of ...</td>\n      <td>introduction artificial intelligence ai is the...</td>\n    </tr>\n  </tbody>\n</table>\n<p>346 rows × 4 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.rename(columns={\"target\":\"target_text\", \"source\":\"source_text\"})\n",
        "df = df[['source_text', 'target_text']]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-01T15:32:54.553629Z",
          "iopub.execute_input": "2023-11-01T15:32:54.553985Z",
          "iopub.status.idle": "2023-11-01T15:32:54.564992Z",
          "shell.execute_reply.started": "2023-11-01T15:32:54.553956Z",
          "shell.execute_reply": "2023-11-01T15:32:54.564068Z"
        },
        "trusted": true,
        "id": "IyItY-3m6wt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# T5 model expects a task related prefix: since it is a summarization task, we will add a prefix \"summarize: \"\n",
        "df['source_text'] = \"summarize: \" + df['source_text']\n",
        "df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-01T15:32:55.670536Z",
          "iopub.execute_input": "2023-11-01T15:32:55.671359Z",
          "iopub.status.idle": "2023-11-01T15:32:55.694662Z",
          "shell.execute_reply.started": "2023-11-01T15:32:55.671324Z",
          "shell.execute_reply": "2023-11-01T15:32:55.693785Z"
        },
        "trusted": true,
        "id": "E-F1Aclm6wt7",
        "outputId": "fa6ec48c-5c94-4c4f-b3d3-0db7867c84b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 5,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                           source_text  \\\n0    summarize: predicting the future of ai with ai...   \n1    summarize: insider attack detection using deep...   \n2    summarize: electronics of artiﬁcial intelligen...   \n3    summarize: life of effective in reducing lung ...   \n4    summarize: keep your dreams alive. understand ...   \n..                                                 ...   \n341  summarize: detecting causes of spatial variati...   \n342  summarize: int elec comp eng issn computed tom...   \n343  summarize: nu journal of humanities social sci...   \n344  summarize: diagnostics of alt are the enzymes ...   \n345  summarize: webology volume number january appl...   \n\n                                           target_text  \n0    we point out several extensions and future wor...  \n1    the stream mining algorithm with decision grap...  \n2    in the literature we ﬁnd different works that ...  \n3    data sources and search strategy systematic li...  \n4    in an organization where human intelligence is...  \n..                                                 ...  \n341  introduction crop yields are affected by many ...  \n342  finally both kenny et al. and wabnitz et al. c...  \n343  whitmore conceived empowerment as an interacti...  \n344  shao et al. applied ultra performance liquid c...  \n345  introduction artificial intelligence ai is the...  \n\n[346 rows x 2 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>source_text</th>\n      <th>target_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>summarize: predicting the future of ai with ai...</td>\n      <td>we point out several extensions and future wor...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>summarize: insider attack detection using deep...</td>\n      <td>the stream mining algorithm with decision grap...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>summarize: electronics of artiﬁcial intelligen...</td>\n      <td>in the literature we ﬁnd different works that ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>summarize: life of effective in reducing lung ...</td>\n      <td>data sources and search strategy systematic li...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>summarize: keep your dreams alive. understand ...</td>\n      <td>in an organization where human intelligence is...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>341</th>\n      <td>summarize: detecting causes of spatial variati...</td>\n      <td>introduction crop yields are affected by many ...</td>\n    </tr>\n    <tr>\n      <th>342</th>\n      <td>summarize: int elec comp eng issn computed tom...</td>\n      <td>finally both kenny et al. and wabnitz et al. c...</td>\n    </tr>\n    <tr>\n      <th>343</th>\n      <td>summarize: nu journal of humanities social sci...</td>\n      <td>whitmore conceived empowerment as an interacti...</td>\n    </tr>\n    <tr>\n      <th>344</th>\n      <td>summarize: diagnostics of alt are the enzymes ...</td>\n      <td>shao et al. applied ultra performance liquid c...</td>\n    </tr>\n    <tr>\n      <th>345</th>\n      <td>summarize: webology volume number january appl...</td>\n      <td>introduction artificial intelligence ai is the...</td>\n    </tr>\n  </tbody>\n</table>\n<p>346 rows × 2 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spliting Dataset"
      ],
      "metadata": {
        "id": "eAePyKJvA9Yv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, test_df = train_test_split(df, test_size=0.2)\n",
        "train_df.shape, test_df.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-01T15:32:56.439084Z",
          "iopub.execute_input": "2023-11-01T15:32:56.440087Z",
          "iopub.status.idle": "2023-11-01T15:32:56.962311Z",
          "shell.execute_reply.started": "2023-11-01T15:32:56.440043Z",
          "shell.execute_reply": "2023-11-01T15:32:56.961354Z"
        },
        "trusted": true,
        "id": "mG60JVrz6wt7",
        "outputId": "e49a8ab1-0cc6-49c1-b6fd-c5192a7f8396"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
          "output_type": "stream"
        },
        {
          "execution_count": 6,
          "output_type": "execute_result",
          "data": {
            "text/plain": "((276, 2), (70, 2))"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading Model"
      ],
      "metadata": {
        "id": "V3SEUaDxBAQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from simplet5 import SimpleT5\n",
        "model = SimpleT5()\n",
        "model.from_pretrained(model_type=\"t5\", model_name=\"t5-base\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-01T15:32:58.810771Z",
          "iopub.execute_input": "2023-11-01T15:32:58.811103Z",
          "iopub.status.idle": "2023-11-01T15:33:34.358708Z",
          "shell.execute_reply.started": "2023-11-01T15:32:58.811078Z",
          "shell.execute_reply": "2023-11-01T15:33:34.357810Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "0b2243525e734f84b068842012a8da4c",
            "a21ac5c9023f4dd293eb3f6ff55715eb",
            "3f135489659941c2ba5fcb3a15916af3",
            "7978b1b147a049c1919f664e658086c6"
          ]
        },
        "id": "cCee6kcr6wt7",
        "outputId": "0c88abf5-ad5e-4c35-ca5d-6b40a3ed6270"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading:   0%|          | 0.00/773k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b2243525e734f84b068842012a8da4c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading:   0%|          | 0.00/1.32M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a21ac5c9023f4dd293eb3f6ff55715eb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading:   0%|          | 0.00/1.18k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3f135489659941c2ba5fcb3a15916af3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading:   0%|          | 0.00/850M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7978b1b147a049c1919f664e658086c6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine Tuning The Model"
      ],
      "metadata": {
        "id": "WJ49AwBJBXFU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.train(train_df=train_df,\n",
        "            eval_df=test_df,\n",
        "            source_max_token_len=128,\n",
        "            target_max_token_len=50,\n",
        "            batch_size=8, max_epochs=5, use_gpu=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-01T15:33:34.360252Z",
          "iopub.execute_input": "2023-11-01T15:33:34.360532Z",
          "iopub.status.idle": "2023-11-01T15:35:13.710963Z",
          "shell.execute_reply.started": "2023-11-01T15:33:34.360507Z",
          "shell.execute_reply": "2023-11-01T15:35:13.710029Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "",
            "896047b6de4b4f628a4c57c0b296ffc3"
          ]
        },
        "id": "mUDEuBEa6wt7",
        "outputId": "06aa4243-87f6-410a-8f8e-d8b31a652a1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation sanity check: 0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n  rank_zero_warn(\n/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n  rank_zero_warn(\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Training: 0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "896047b6de4b4f628a4c57c0b296ffc3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validating: 0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validating: 0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validating: 0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validating: 0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validating: 0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! ( cd outputs; ls )"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-01T15:35:13.712792Z",
          "iopub.execute_input": "2023-11-01T15:35:13.713145Z",
          "iopub.status.idle": "2023-11-01T15:35:14.762214Z",
          "shell.execute_reply.started": "2023-11-01T15:35:13.713104Z",
          "shell.execute_reply": "2023-11-01T15:35:14.761015Z"
        },
        "trusted": true,
        "id": "dNUlFnAf6wt7",
        "outputId": "f2ea10c5-ca3f-46f3-d192-4179b325a2a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "simplet5-epoch-0-train-loss-4.1447-val-loss-3.7157\nsimplet5-epoch-1-train-loss-3.7984-val-loss-3.6766\nsimplet5-epoch-2-train-loss-3.5484-val-loss-3.6781\nsimplet5-epoch-3-train-loss-3.3369-val-loss-3.6882\nsimplet5-epoch-4-train-loss-3.1244-val-loss-3.7309\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's load the trained model from the local output folder for inferencing:\n",
        "model.load_model(\"t5\",\"/kaggle/working/outputs/simplet5-epoch-1-train-loss-3.7984-val-loss-3.6766\", use_gpu=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-01T15:36:02.259455Z",
          "iopub.execute_input": "2023-11-01T15:36:02.259904Z",
          "iopub.status.idle": "2023-11-01T15:36:05.272860Z",
          "shell.execute_reply.started": "2023-11-01T15:36:02.259867Z",
          "shell.execute_reply": "2023-11-01T15:36:05.272040Z"
        },
        "trusted": true,
        "id": "qxiwfROB6wt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_to_summarize = df[\"source_text\"][0]\n",
        "\n",
        "generated_text = model.predict(text_to_summarize)\n",
        "\n",
        "print(generated_text)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-01T15:36:06.035978Z",
          "iopub.execute_input": "2023-11-01T15:36:06.036349Z",
          "iopub.status.idle": "2023-11-01T15:36:08.232004Z",
          "shell.execute_reply.started": "2023-11-01T15:36:06.036317Z",
          "shell.execute_reply": "2023-11-01T15:36:08.231024Z"
        },
        "trusted": true,
        "id": "R-HSOhA-6wt8",
        "outputId": "d9c16f4b-2a44-4b07-8081-51b7724fb7e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "Token indices sequence length is longer than the specified maximum sequence length for this model (5600 > 512). Running this sequence through the model will result in indexing errors\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "['ai is an algorithm that can be used to predict the future of ai by analyzing the data in real time. this approach was presented in the ieee bigdata competition in fall and it has been widely adopted in many other fields such as artificial intelligence and machine learning.']\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculating Rouge Score"
      ],
      "metadata": {
        "id": "1IwEx2n63HoC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge import Rouge\n",
        "\n",
        "# Example: reference and generated summaries\n",
        "reference_summary = [df[\"target_text\"][0]]  # Place the reference summary in a list\n",
        "generated_summary = generated_text  # Keep the generated summary as a list\n",
        "\n",
        "# Creates a Rouge object\n",
        "rouge = Rouge()\n",
        "\n",
        "# Calculates ROUGE scores\n",
        "scores = rouge.get_scores(generated_summary, reference_summary)\n",
        "\n",
        "print(scores)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-01T15:36:08.233619Z",
          "iopub.execute_input": "2023-11-01T15:36:08.233928Z",
          "iopub.status.idle": "2023-11-01T15:36:08.260076Z",
          "shell.execute_reply.started": "2023-11-01T15:36:08.233901Z",
          "shell.execute_reply": "2023-11-01T15:36:08.259048Z"
        },
        "trusted": true,
        "id": "o9SkWyM36wt8",
        "outputId": "9afe6eb7-4db2-47a9-c9eb-afb6f5820f97"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "[{'rouge-1': {'r': 0.2564102564102564, 'p': 0.23809523809523808, 'f': 0.2469135752537724}, 'rouge-2': {'r': 0.0392156862745098, 'p': 0.041666666666666664, 'f': 0.0404040354086324}, 'rouge-l': {'r': 0.1794871794871795, 'p': 0.16666666666666666, 'f': 0.17283950117969835}}]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "#User Inputs PDF(Pipeline)"
      ],
      "metadata": {
        "id": "6-RYqPbS6wt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymupdf\n",
        "!pip install pycryptodome"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-01T15:38:10.929465Z",
          "iopub.execute_input": "2023-11-01T15:38:10.929858Z",
          "iopub.status.idle": "2023-11-01T15:38:33.281147Z",
          "shell.execute_reply.started": "2023-11-01T15:38:10.929827Z",
          "shell.execute_reply": "2023-11-01T15:38:33.279947Z"
        },
        "trusted": true,
        "id": "0VQbo0D-6wt9",
        "outputId": "efcdee8d-ceb1-497b-f800-6f34fff97805"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nRequirement already satisfied: pymupdf in /opt/conda/lib/python3.10/site-packages (1.23.5)\nRequirement already satisfied: PyMuPDFb==1.23.5 in /opt/conda/lib/python3.10/site-packages (from pymupdf) (1.23.5)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nRequirement already satisfied: pycryptodome in /opt/conda/lib/python3.10/site-packages (3.18.0)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Python script extracts and preprocesses text from a PDF file, excluding images, using OCR and regular expressions. It also removes tables, formulas, emails, URLs, and performs various text cleaning operations and creates an user input pipeline"
      ],
      "metadata": {
        "id": "PlPbDMuICUV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz  # PyMuPDF\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "import re\n",
        "import string\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import nltk\n",
        "import os\n",
        "\n",
        "pdf_path = \"/kaggle/input/test-dataset/Virtual_Reality_in_Chemical_Engineering_Education.pdf\"\n",
        "\n",
        "# Function to perform OCR on an image and extract text\n",
        "def extract_text_from_image(image_path):\n",
        "    image = Image.open(image_path)\n",
        "    text = pytesseract.image_to_string(image)\n",
        "    return text\n",
        "\n",
        "# Function to extract text from the PDF, excluding images\n",
        "def extract_and_preprocess_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    pdf_document = fitz.open(pdf_path)\n",
        "\n",
        "    references_section_started = False  # Flag to track if references section started\n",
        "\n",
        "    for page_number in range(pdf_document.page_count):\n",
        "        page = pdf_document.load_page(page_number)\n",
        "        page_text = \"\"\n",
        "\n",
        "        # Extract the image from the page and save it as a PNG\n",
        "        pix = page.get_pixmap()\n",
        "        image = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
        "        image_path = \"temp_image.png\"\n",
        "        image.save(image_path)\n",
        "\n",
        "        # Extracts text from the saved image using OCR\n",
        "        page_text += extract_text_from_image(image_path)\n",
        "\n",
        "        # Checks if any of the references start keywords are present in the page text\n",
        "        if any(keyword in page_text for keyword in references_start_keywords):\n",
        "            references_section_started = True\n",
        "\n",
        "        # Appends the page text if references section is not started\n",
        "        if not references_section_started:\n",
        "            text += page_text\n",
        "\n",
        "        # Removes the temporary image file\n",
        "        os.remove(image_path)\n",
        "\n",
        "    # Preprocess the extracted text\n",
        "    text = preprocess_text(text)\n",
        "\n",
        "    return text\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Sentence Tokenization\n",
        "    sentences = sent_tokenize(text)\n",
        "\n",
        "    # Initializes an empty list to store preprocessed sentences\n",
        "    preprocessed_sentences = []\n",
        "\n",
        "    for sentence in sentences:\n",
        "\n",
        "        # Use of regular expressions to remove tables and formulas (customize as needed)\n",
        "        table_pattern = r\"(?i)(?:Table|Tab\\.|Fig\\.)\\s+\\d+\\s*[:\\s-]*\\s*(.*?)\\s*(?=(?:Table|Tab\\.|Fig\\.|\\n|\\Z))\"\n",
        "        sentence = re.sub(table_pattern, \"\", sentence)\n",
        "\n",
        "        formula_pattern = r\"(\\$\\$[\\s\\S]*?\\$\\$|\\$[\\s\\S]*?\\$)\"\n",
        "        sentence = re.sub(formula_pattern, \"\", sentence)\n",
        "\n",
        "        # Removing E-mails\n",
        "        email_pattern = r'\\S+@\\S+\\.\\S+'\n",
        "        sentence = re.sub(email_pattern, '', sentence)\n",
        "\n",
        "        # Removeing Urls\n",
        "        url_pattern = r'https?://\\S+|www\\.\\S+'\n",
        "        sentence = re.sub(url_pattern, '', sentence)\n",
        "\n",
        "        # Lowercasing\n",
        "        sentence = sentence.lower()\n",
        "\n",
        "        # Removes Special Characters\n",
        "        pattern = r'[^\\w\\s]'\n",
        "        sentence = re.sub(pattern, ' ', sentence)\n",
        "\n",
        "        # Removes single alphabets\n",
        "        sentence = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', sentence)\n",
        "\n",
        "        # Removing Numbers\n",
        "        sentence = re.sub(r'\\d+', '', sentence)\n",
        "\n",
        "        # Removing Punctuations\n",
        "        sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "        # Removing Extra Spaces\n",
        "        sentence = \" \".join(sentence.split())\n",
        "\n",
        "        # Appends the preprocessed sentence to the list\n",
        "        preprocessed_sentences.append(sentence)\n",
        "\n",
        "    # Joining the preprocessed sentences back into a single string with a space as delimiter\n",
        "    preprocessed_text = '. '.join(preprocessed_sentences)\n",
        "\n",
        "    return preprocessed_text\n",
        "\n",
        "# Defineing the keywords that indicate the start of the references section\n",
        "references_start_keywords = [\"Bibliography\", \"REFERENCES\", \"BIBLIOGRAPHY\", \"References\", \"Acknowledgments\",\n",
        "                             \"ACKNOWLEDGMENTS\", \"Reference\", \"REFERENCE\", \"Authors’ Biography\"]\n",
        "\n",
        "# Extracts text from the specified PDF file and preprocess it\n",
        "preprocessed_text = extract_and_preprocess_text_from_pdf(pdf_path)\n",
        "\n",
        "print(preprocessed_text)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-01T15:39:25.929095Z",
          "iopub.execute_input": "2023-11-01T15:39:25.929487Z",
          "iopub.status.idle": "2023-11-01T15:39:38.173222Z",
          "shell.execute_reply.started": "2023-11-01T15:39:25.929453Z",
          "shell.execute_reply": "2023-11-01T15:39:38.172193Z"
        },
        "trusted": true,
        "id": "ByUBo4Je6wt9",
        "outputId": "a16aff4b-0082-48fa-cdfb-1c57c54cb912"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "researchgate virtual reality in chemical engineering education reprited from the proceedings of the american society for engineering eduction iino odiana sestonal conference purdue university match tual reality in chemical engineering education john bell scott fogler department of chemical engineetis university of michigan ann arbor npossible to achieve. in order to take full advantage of this new technology virtual reality based simulator vicher ly being developed at the university of michigan chemical engineering department in order to aid in the instruction of chemical reactor engineering. while virtual reality has been recently employed in few educational applications grade school and high school levels and for advanced operator training virtual surgery flight simulation the program presented here is the first known application of virtual reality to chemical engineering education backgro virtual reality vr is newly emerging computer interface designed to make the user believe that they are actually inside of the computer generated environment as opposed to being an external observer looking in. an effective virtual environment must also be highly interactive giving the user as much conttol as possible over their surroundings. high degrees of immersion are accomplished via fast high resolution graphics three dimensional audio and video interfaces head mounted display devices wired gloves and other clothing tactile feedback and numerous psychological techniques. although the concept of virtual reality has been around for almost thirty years until recently its use has been limited specialized research labs and those with large computing budgets such as the military. within the past few years however number of inexpensive hardware and software vr products have been developed which has brought virtual reality within reach of the average researcher and even home hobbyist furthermore as virtual reality grows in popularity the economy of scale will bring new nd more powerful features within the reach of educational users. although high quality solutions are not yet affordable and affordable solutions are not yet high quality we feel it prudent to begin developing virtual realty based educational applications today so that we will be prepated for the equipment which will be available tomorrow. overview of vicher vieher viral chemical reaction module is an educational application of virtual reality designed to aid in the instruction of undergraduate chemical reaction the goals chemical reactor design studen studied in class can explore firsthand the concepts which they have provide in depth reactor design and computer programming taining who are helping to develop vicher and develop knowledge base the application of virtual reality techniques to educational applications. this knowledge base may be the strongest benefit of the project as it can then be applied to more complex applications und more advanced hardware in future developmes vicher is being developed using two mhz pentium based personal computers. the two machines are configured with different sets of peripheral hardware in order address current as well as future audiences. the first machine uses no special hardware other than fast video board and joystick and is based on the microsoft windows environment this class of hardware is already in the hands of many students and undergraduate laboratories and should become common within the next year or so. the second machine contains specialized ultrhigh speed video board and spatiaized sound audio card and is further equipped with head mounted display ut gogeles and other vr devices. this class of hardware will not be common for several years but it allows us to deliver much higher quality product prepared for the day when computer capabilities increase these hard made as compromise between delivering the best performance possible and developing product which can be placed is of as many students as possible as quickly as possible. vicher will run on either platform and can be easily ported to higher quality equipment such as silicon graphics workstations ata later date the virtual environment being modeled in vieher consists of small portion of modes chemical plant plus two microscopic exploration areas. the rooms consist of welcome center in which users lea how to use the program and receive other pertinent iormation reactor room where users can control and observe an operating reactor. nd debriefing room designed to test student mastery of the concepts presented. the microscopic areas are the inside and the outside of catalyst pellet. users interface with vicher using joystick for movement mouse for activating objects and requesting information and keyboard for various other tasks. users ean receive information on any object or area by using the right mouse button. in the windows environment this brings up separate window with the appropriate help text. this help is also linked to other help screens via hypertext interface. work is currently underway to implement similar feature in the dos version the left mouse button is used activate objects such as the television or reactor controls where activate takes on meaning appropriate tothe object. the pictures on the walls can be activated which provides teleport to the location pictured variation of this is to fly through the pictures which also provides teleport. we have found the teleports to be very effective navigational technique and intend to incorporate them in all future areas. wher using the head mounted display head tracking device allows the user t simply look where they want to go and push the stick forwatd to move in that diection this has been found to be the simplest and most effective navigation technique. another strong benefit of the head mounted display is the sensory deprivation effeet when users are lunable to see the real world they become much more immersed in the virtual one. the welcome center the first room which users encounter is the welcome center containing tables chairs desk pictures books and working television set. the purposes of the welcome center tte wofold. the first is to overcome the disorientation problems which some users experience when first encountering virtual reality. the welcome center is designed to be simple familiar environment in which users ean become comfortable with the virtual reality hardware and software before moving on to more complex and possibly abstract renter in which students can get educational input from the pictures books and television. this latter goal has been reached to greater extent in the windows version of vicher than in the dos due to various technical considerations. we have also discovered that the welcome center makes good base of operations from which to explore other areas. future expansions of vicher will therefore all branch out from the welcome center. some of the features of the welcome center will be expanded to other rooms as vicher the reactor room the primary engineering area is currently the reactor room which contains vertical straight through transport reactor and is associated catalyst regenerator and control ciples being illustrated in the reactor room are what does industrial reactor really look like and how does it operate the effects of flowrates on coking and decoking of catalyst pellets and the subsequent effect on reaction rate yield fractional conversion and other reaction properties and the shrinking core model of catalyst decay and regeneration. in the reactor room students ean operate various controls and observe the effects on reactor performance students can enter inside of the equipment travel through the pipes etc. in order to observe the activity inside the equipment or they can simply tur the equipment transparent via the control panel. in wansparent mode the students can see into the interior from any viewpoint but cannot see out the other side as if the equipment were fabricated from one way glass. in general we have found this to be more effective than entering the equipment as it provides the students with wider field of view the reactor contains catalyst pellets which rise faster or slower according to the user controllable reactant flowrate. as the pellets rise they become darker as result of coke deposits which are byproduct of the reaction taking place. the longer the pellets take to travel through the reactor the dirtier they become. when the catalyst pellets reach the top of the reactor they enter into the catalyst regeneration unit where they are inter current steam. again the steam flowrate is controllable which lyst pellets speed of travel and thereby de coking rate. operating the wols outside of proper range can result in pellets building up in either the reactor of regenerator or else getting successively dirtier due to inefficient regeneration activity microscopic areas the two microscopic exploration areas are the outside and inside of the catalyst pellets. the educational goal of these two areas is to present the mechanism of catalytic reaction whereby reactants must diffuse into the catalyst pores and absorb onto the catalyst surface before reaction can occur followed by the desorption and exiting diffusion of the product molecules. in addition the current implementation also includes an undesired competing reaction and coke formation. nt on the outside of the catalyst pellets can observe the diffusion of reactants and out ofthe pellet. this atea also serves as transition from the large scale world into the microscopic scale catalyst pore. inside the pores of the catalyst pellets the students can observe the mechanism for catalyzed reaction as outlined above as well as diffusion effects. the catalyst pellet continues to move from the reactor to the regenerator and back while the user is inside thereby allowing observation of the entire reaction regeneration cycle the debriefing room the purpose in developing the debriefing room was to question the students in order to their mastery of the concepts to produce grade for running the simula spire them co go back to the engineering areas and further explore issues whi grasp the first time through. to date this room has not delivered its full potential ext in graphical environment. revent developments however promise to make this much more functional area in the near future. preliminary results two of the three stated goals of producing vicher have been met the students developing the programs have learned great deal from the experience and considerable base of techniques has been developed which will be valuable in future applicati ling the coverage of vieher to new areas. as for the third sta goal teaching reaction engineering the fist test ofthe program effectiveness will occur just after the submission of this paper but will be covered in the oral presentation. as ditional unplanned benefit has been greater understanding of the hunvan factors and. psychological issues pertaining to virtual reality the students who have been helping to produce vicher have not only gained much better understanding of the underlying reaction engineering principles but have also gained valuable skills in programming computer graphics three dimensional modeling systems management project management and other computer techniques related to virtual reality. several dozen other students and practicing engineers have tested vieher and their feedback has been instrumental in guiding the development of the program. although vicher incorporates logging and videotaping of user actions the most effective data collection technique to date has been direct observation. user response to vicher has been highly favorable much of the knowledge gained in developing vicher is technical in nature such as how. to move multiple complex objects in realistic manner at reasonable speeds. for virtual reality to be effective the graphics images must be recalculated and re displayed several times per second ideally to frames per second. this technique has been nplemented both in moving the catalyst pellets through the reaction equipment and also moving the molecules within the catalyst pores. note that in both these situations the objects in question also change form as the chemical reactions progress. other features which have been developed and will be incorporated in future expans lude the nplementation of functional television set with both pictures and sound and the iol panel with functional buttons and gauges. another area in which knowledge has been gained involves human factors issues. recall thatthe essence of virtual reality is to make the user believe that they are actually within the computer generated environment and that said environment is real. ic is therefore vitally important to understand what features of virtual world most enhance the believability and realism of the overall experience. for example the origina technique for moving from room to room involved walking down hallway. the purpose of the hallway was to provide smooth logical transition from area to area in order minimize the disorientation sometimes associated with virtual reality. our experience has shown that many users had difficulty navigating the hallways and that the hallways do not add significantly the experience. on the contrary once the teleporting. pictures were implemented most users preferred to use the teleports and have experienced very few disorientation problems with this interface. accordingly all hallways are currently being replaced with teleport developing the proper computer human interface is also crucial to an effective virtual world. in order to be most effective virtual reality implementation should have an face which is as intuitive as possible so thatthe user may more easly forget they are using computer. the best interface found for vicher is combination of the joystick nd the mouse. the keyboard has been found to be poor interface for virtual worlds the head mounted display unit as the user is unable to see the keyboard easily. the joystick on the other hand is especially effective in junction with the head mounted display as the user merely looks in the desired direction and pushes the stick forward. the only drawback to the joystick as an interface device is that not all potential users have joysticks attached to their computers and some environments such as undergraduate computing labs perceive them as toy therefore resist their implementation urrent and planned developments one area in which vicher is currently weak is inthe presentation of text based material such as formulas equations and definitions as opposed fo presenting situations and. objects. this is due tothe fact that vicker is primarily graphical pictures as opposed to text. the problem is particularly severe when using the head mounted display as text output is displayed on an alternate display ot visible from within the hmd. the problem is further complicated by the desire to provide both dos and windows solutions. new techniques have recently been developed however for presenting textual ormation in graphical format specifically new methods for displaying pictures of major development goals for the next three months is to uilize these new techniques to greatly improve the informational capabilities of vicher using wall sized virtual televisions forthe presentation of educational materials another major development effort is to convert the navigational interface from hallways. to teleports. this will allow the rooms to be easily reorganized into areas of educational study and several new rooms and new areas to be added. the new structure will sorporate studies or libraries between the welcome center and the engineering exploration areas. these study rooms will be where the students are presented with the background engineering information corresponding to each area. one option be explored is whether or not students should be forced to review the background lormation before proceeding on the engineering ateas. likewise examination rooms will be added after the engineering areas to test students mastery of the material being neering area to be added will provide for the study of heat effect isothermal operation in chemical reaction engineering conclusion virtual reality based computer simulation program is currently under development id in the instruction of undergraduate chemical reaction engineering. at this time the primary engineering topics covered inelude the operation of straight through transport reactor and associated catalyst regenerator the effects of varying flowrates on catalyst coking and reactor performance the shrinking core model of catalyst decay and regeneration and the mechanism of catalytic reaction including diffusion absorption nd desorption processes. the major benefits gathered at this stage of development are the knowledge base of virtual reality techniques and how best to apply them educational applications and the raining and experience of the students who are helping to develop the programs additional informational interfaces are being added at the time of this writing and should be in place bythe time this paper is presented. also within the next few months new areas will be added to the simulator including an area for the study of heat effects non isothermal operation in chemical reactor engineering and additional rooms for the presentation of engineering information and for testing of students performance. the first reaction engineering class will soon have chance to experience the simulator and their feedback will be used to guide the further development of vicker\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Predicted Text**"
      ],
      "metadata": {
        "id": "7kabQPNB28bR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(preprocessed_text)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-01T15:39:38.175113Z",
          "iopub.execute_input": "2023-11-01T15:39:38.175921Z",
          "iopub.status.idle": "2023-11-01T15:39:40.595566Z",
          "shell.execute_reply.started": "2023-11-01T15:39:38.175882Z",
          "shell.execute_reply": "2023-11-01T15:39:40.594602Z"
        },
        "trusted": true,
        "id": "VsWPLziL6wt9",
        "outputId": "d76ff0f2-8cf5-4bf5-e293-d35ba709d3b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 20,
          "output_type": "execute_result",
          "data": {
            "text/plain": "['the and is to provide a will be an area for the study of heat effects non isothermal operation in chemical reaction engineering. this virtual reality as well as students their feedback will be used to guide the further development of vicher.s alsoi these aree however the first room contains tables chairs desk pictures books and working television set. that the second room has been designed to facilitate other areas the the which  they']"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8PtrsiIx6wt9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
